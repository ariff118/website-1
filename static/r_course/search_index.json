[
["about-the-class.html", "Reproducible data treatment with R An introduction About the class Objectives of the class Prerequisites Teaser Further readings Motivations", " Reproducible data treatment with R An introduction Colin Bousige 03/07/2019 About the class Objectives of the class The goal of this class is that at the end, the students are able to: Treat their data with the free and open source language R, i.e.: Read, browse, manipulate and plot their data Model or simulate their data Make automatic reporting through Rmarkdown and/or Jupyter notebooks Build a graphical interface with Shiny to interact with their data and output something (a value, a pdf report, a graph…) Prerequisites Coding skills: none expected The students should come with a laptop with admin rights (i.e. you should be able to install stuff) Teaser You want to be able to produce interactive plots like these in an automatic experimental report? You want to produce publication-quality graphs like these? You want to be able to build graphical interfaces like this to help you in your data treatment? Stay tuned! You’ve come to the right place. Further readings This class is indented to provide the students with the tools to handle themselves with R, Rmarkdown and Shiny, and not to provide an extensive review of everything that is possible with R. To go further: R manual on CRAN A digested version Some cheatsheets The R Graph Gallery The tidyverse website The ggplot cheatsheet Another one Another one quite extensive Rmarkdown cheatsheet Rmarkdown cookbook And as always, if you have a question, Google is your friend! Motivations Reproducible data treatment: why it matters In 2016, Nature conducted a survey of 1576 researchers who took a brief online questionnaire on reproducibility in research. According to the survey, more than 70% of researchers have tried and failed to reproduce another scientist’s experiments, and more than half have failed to reproduce their own experiments. 1 “Although 52% of those surveyed agree there is a significant ‘crisis’ of reproducibility, less than 31% think failure to reproduce published results means the result is probably wrong, and most say they still trust the published literature.”2 Replicability and reproducibility are some of the keys to scientific integrity. Establishing a workflow in which your data are always treated in the same manner is thus a way to: Reduce error risks inherent to human manipulation Keep track of all the treatments you perform on your data and document your methodology Help you to make sense of all your data, and avoid disregarding some data (hence help you keep your scientific integrity) Gain tremendous amounts of time It is the objective of this class to provide you the tools necessary to work with this philosophy. Why with R and not python? The eternal question… R was originally designed by statisticians for statisticians and in my opinion suffers from this “statistics only” label that sticks to it. Python is a wide spectrum programming language with very efficient numerical libraries used in the computer science community. R is focused on data treatment, statistics and representation. In R, the object is the data, and base R allows you to read, treat, fit and plot your data very easily – although you will still most certainly need additional packages. So with python, you can do everything, including treating and analyzing scientific data – with the right packages. With R, you can do less but do very well what you do, and in my opinion more seamlessly (probably because I learned and used R for years before starting with python…). Each language has his own strengths and weaknesses. To my tastes, I would say that python and R compare like that (although a pythonist would probably say the opposite): R Python Free and open source ✔✔✔ ✔✔✔ IDE ✔✔✔ ✔✔✔ Large code repository ✔✔✔ ✔✔✔ Large community ✔✔✔ ✔✔✔ Notebooks ✔✔✔ ✔✔✔ Machine Learning ✔✔✔ ✔✔✔ Performances ✔ ✔✔✔ Ease of installation and maintenance ✔✔✔ ✔ Data visualization ✔✔✔ ✔ Statistical analysis ✔✔✔ ✔ Multi-purpose ✔ ✔✔✔ Syntax, productivity, flexibility ✔ ✔✔✔ Rmarkdown ✔✔✔✔✔✔✔✔✔✔ ✔ Well, it’s all very subjective, really. In the end, I still use both languages, each one for a different purpose: Let’s say I want to produce an initial atomic configuration for a molecular dynamics simulation, or read a molecular dynamics trajectory and compute some quantities such as a pair correlation or a mean square displacement: python (or even C, if I need to treat large trajectories). Now if I want to make sense of some experimental measurements or results of simulations, do some fits and produce publication-quality graphs or experimental reports: R. Both languages are great and being able to use both is the best thing that can happen to you (relatively speaking) – especially since you can combine them in Rmarkdown using the reticulate package, which we will see later in this class. So, since my goal is to provide you with tools for seamlessly read, make sense, and plot your data in the reproducible science philosophy, let’s go with R. From wikipedia↩ https://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970↩ "],
["getting-ready.html", "1 Getting ready 1.1 The easy way 1.2 The more advanced way 1.3 In any case: install LaTeX 1.4 Setting up the environment", " 1 Getting ready 1.1 The easy way Download and install R Download and install Rstudio You’re good to go. Launch Rstudio, click File &gt; New File &gt; R script. Write whatever you want in the “Source code” panel, and run it by selecting it and hitting ⌘+⏎ (Ctrl+⏎ on Windows). If no text is selected, hitting ⌘+⏎ will launch the current line. The code output will be seen in the “R Console” panel if it’s a text, or in the “Graph” panel if it’s a graph. A list of all defined variables and functions is available in the “Environment” panel. More on the Rstudio cheatsheet. 1.2 The more advanced way If you don’t want to use Rstudio but rather want to keep with your favorite text editor, like I do3 (Sublime Text, Atom, Visual Studio Code…) I still recommend downloading and installing R via CRAN (I had some packages problems due to a homebrew installation). To be fully operational with Rmarkdown files without using Rstudio, you need to install pandoc: brew install openssl brew install pandoc brew install pandoc-citeproc pip install pandoc-eqnos pip install pandoc-fignos pip install pandoc-tablenos 1.3 In any case: install LaTeX A full \\(\\LaTeX\\) distribution (emphasis on full) will be needed to knit markdown files to PDFs: Windows: go here and download the Net Installer to install the complete distribution Mac: go here or type brew cask install mactex in the terminal if you have Homebrew installed Linux: here fore example 1.4 Setting up the environment Make sure you have the following packages installed by launching (⌘+⏎ or Ctrl+⏎) the following commands: install.packages(&quot;rstudioapi&quot;) install.packages(&quot;devtools&quot;) install.packages(&quot;tools&quot;) install.packages(&quot;tidyverse&quot;) install.packages(&quot;rmarkdown&quot;) install.packages(&quot;knitr&quot;) install.packages(&quot;shiny&quot;) install.packages(&quot;openxlsx&quot;) Later on, a package can be loaded by calling: library(package_name) or by checking it in the “Graph” panel under the “Packages” tab. If you want to access a function from a given package without loading it (or because several packages define the same function and you want to specify which to use), type: package_name::function_name(parameters) If you want to access the documentation on a given package, click the link on this package in the “Packages” tab. In a more general way, help on a function is accessed by typing in ?function_name, the help appearing in the “Graph” panel. To get the path of your working environment, type in: getwd() ## [1] &quot;/Users/colin/Travail/Enseignements/R&quot; To set it to the directory you want: setwd(&quot;your/path/&quot;) To set it to the directory the current file is in, type in: setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) "],
["simple-variables.html", "2 Simple variables 2.1 Scalars and booleans 2.2 Strings 2.3 Exercises", " 2 Simple variables In R, the variable attribution is done through the arrow operator &lt;- instead of the = one – for historical reasons. The equal sign, =, would still work though, but you should just take up the habit of using &lt;-. In reality, scalar numbers don’t exist in R, they are simply 1 element vector: this is why [1] is printed in the following outputs. 2.1 Scalars and booleans Separate in-line instructions with a ; or just skip a line. Different ways of defining a scalar, as a double or an integer: x &lt;- 1; x ## [1] 1 typeof(x) ## [1] &quot;double&quot; class(x) ## [1] &quot;numeric&quot; y &lt;- floor(1.2); y; typeof(y); class(y) ## [1] 1 ## [1] &quot;double&quot; ## [1] &quot;numeric&quot; z &lt;- as.integer(1.2); z; typeof(z); class(z) ## [1] 1 ## [1] &quot;integer&quot; ## [1] &quot;integer&quot; 2.1.1 Special values R handles infinity, NaN, and has \\(\\pi\\) defined. Missing numbers are handled through the NA keyword. pi; 10/0; -10/0; 0/0; is.na(NA) ## [1] 3.141593 ## [1] Inf ## [1] -Inf ## [1] NaN ## [1] TRUE 2.1.2 Booleans Booleans are handled with the TRUE and FALSE keywords. Any number non 0 is equivalent to TRUE, 0 is FALSE. z &lt;- TRUE; typeof(z) ## [1] &quot;logical&quot; as.logical(1) ## [1] TRUE as.logical(0) ## [1] FALSE x == y # is equal ## [1] TRUE x != y # is not equal ## [1] FALSE x &lt; y # is smaller than ## [1] FALSE x &lt;= y # is smaller or equal than ## [1] TRUE x == y &amp; x &lt; y # operator &quot;and&quot; ## [1] FALSE x == y || x &lt; y # operator &quot;or&quot; ## [1] TRUE 2.1.3 Complex values 1+i ## [1] 32 1+1i ## [1] 1+1i exp(1i*pi) ## [1] -1+0i sqrt(-1) ## Warning in sqrt(-1): NaNs produced ## [1] NaN sqrt(-1 + 0i) ## [1] 0+1i Im(exp(1i*pi)) ## [1] 1.224647e-16 2.2 Strings A string is defined between quotation marks &quot;string&quot;. Here are some operations on strings : phrase &lt;- &quot; Hello World &quot; # definition of a string paste(&quot;phrase =&quot;, phrase, &quot;, class(phrase) =&quot;, class(phrase)) ## [1] &quot;phrase = Hello World , class(phrase) = character&quot; substr(phrase, 2, 5) # sub-string ## [1] &quot;Hell&quot; paste(tolower(phrase), toupper(phrase), sep=&quot; - &quot;) # change case ## [1] &quot; hello world - HELLO WORLD &quot; sub(&quot;o&quot;, &quot;a&quot;, phrase) # change the first occurrence of &quot;o&quot; in &quot;a&quot; ## [1] &quot; Hella World &quot; gsub(&quot;o&quot;, &quot;a&quot;, phrase) # change all occurrences of &quot;o&quot; in &quot;a&quot; ## [1] &quot; Hella Warld &quot; trimws(phrase) # trim white spaces ## [1] &quot;Hello World&quot; phrase2 &lt;- &quot;1234&quot; phrase2 - 4321 # won&#39;t work: string - double ## Error in phrase2 - 4321: non-numeric argument to binary operator as.numeric(phrase2) - 4321 # conversion of string to double ## [1] -3087 For more complex operations, see the stringr package or the string cheatsheet. 2.3 Exercises What will be the output of the following entries? x &lt;- &quot;100&quot;; y &lt;- 99.6; x - ceiling(y) Show output ## Error in x - ceiling(y): non-numeric argument to binary operator 1 / sin(as.numeric(x) - ceiling(y)) Show output ## [1] Inf cos(pi/2)==cos(3*pi/2) Show output ## [1] FALSE cos(pi/2)-cos(3*pi/2) Show output ## [1] 2.449294e-16 all.equal(cos(pi/2),cos(3*pi/2)) Show output ## [1] TRUE "],
["vectors.html", "3 Vectors 3.1 Different ways of defining a vector 3.2 Principal operations on vectors 3.3 Exercises", " 3 Vectors R is a vectorized language with built-in arithmetic and relational operators, mathematical functions and types of number. It means that each mathematical function and operator works on a set of data rather than a single scalar value as traditional computer language do, and thus formal looping can usually be avoided. 3.1 Different ways of defining a vector x &lt;- c(1,5,3,12,4.2,&quot;skdjnc&quot;); x # x is a vector of strings ## [1] &quot;1&quot; &quot;5&quot; &quot;3&quot; &quot;12&quot; &quot;4.2&quot; &quot;skdjnc&quot; x &lt;- c(1,5,3,12,4.2); x # x is a vector of doubles ## [1] 1.0 5.0 3.0 12.0 4.2 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 1:10*.1 # no need to loop on the elements to multiply them! ## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1:10 + 1:10*.5 # or to add/subtract/multiply vectors ## [1] 1.5 3.0 4.5 6.0 7.5 9.0 10.5 12.0 13.5 15.0 1:10*1:10 ## [1] 1 4 9 16 25 36 49 64 81 100 seq(-10,10,by=.5) ## [1] -10.0 -9.5 -9.0 -8.5 -8.0 -7.5 -7.0 -6.5 -6.0 -5.5 -5.0 ## [12] -4.5 -4.0 -3.5 -3.0 -2.5 -2.0 -1.5 -1.0 -0.5 0.0 0.5 ## [23] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 ## [34] 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0 seq(-10,10,length=6) ## [1] -10 -6 -2 2 6 10 seq(-10,10,along=x) ## [1] -10 -5 0 5 10 rep(0,10) ## [1] 0 0 0 0 0 0 0 0 0 0 rep(c(0,2), 5) ## [1] 0 2 0 2 0 2 0 2 0 2 rep(c(0,2),each=5) ## [1] 0 0 0 0 0 2 2 2 2 2 rnorm(10, mean=3, sd=1) # vector with 10 random values ## [1] 4.550409 3.623000 3.162134 3.364277 2.525439 1.675451 2.844811 ## [8] 2.623984 2.679005 2.776677 3.2 Principal operations on vectors x &lt;- c(1,5,3,12,3,4.2) y &lt;- c(a=0,b=2,c=1,d=9,e=10,f=-1) # each element can be named x; y ## [1] 1.0 5.0 3.0 12.0 3.0 4.2 ## a b c d e f ## 0 2 1 9 10 -1 names(x);names(y) ## NULL ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; 3.2.1 Accessing values !!! In R, indexes numbering start at 1 !!! # accessing by indexes x[1]; y[4]; ## [1] 1 ## d ## 9 # accessing by name y[c(&#39;b&#39;,&#39;d&#39;)]; y[[&#39;c&#39;]] ## b d ## 2 9 ## [1] 1 # access index 1, 5 and 2 x[c(1,5,2)] ## [1] 1 3 5 # remove elements 1 and 3 x[-c(1,3)] ## [1] 5.0 12.0 3.0 4.2 3.2.2 Sorting # ascending sort(x) ## [1] 1.0 3.0 3.0 4.2 5.0 12.0 # descending sort(x, decreasing = TRUE) ## [1] 12.0 5.0 4.2 3.0 3.0 1.0 # find the order of the indexes of the sorting order(x); x[order(x)] ## [1] 1 3 5 6 2 4 ## [1] 1.0 3.0 3.0 4.2 5.0 12.0 # find duplicates duplicated(x) ## [1] FALSE FALSE FALSE FALSE TRUE FALSE # remove duplicates unique(x) ## [1] 1.0 5.0 3.0 12.0 4.2 # choose 3 random values sample(x, 3) ## [1] 5 12 3 3.2.3 Maximum and minimum # maximum of x and its index x; max(x); which.max(x) ## [1] 1.0 5.0 3.0 12.0 3.0 4.2 ## [1] 12 ## [1] 4 # minimum of y and its index y; min(y); which.min(y) ## a b c d e f ## 0 2 1 9 10 -1 ## [1] -1 ## f ## 6 # range of a vector range(x) ## [1] 1 12 3.2.4 Mathematical operations x + 2 # addition of a value to all elements ## [1] 3.0 7.0 5.0 14.0 5.0 6.2 x*2 # multiplication / division ## [1] 2.0 10.0 6.0 24.0 6.0 8.4 x%/%3 # integer division ## [1] 0 1 1 4 1 1 sqrt(abs(cos(x))) # math functions apply on all elements ## [1] 0.7350526 0.5325995 0.9949837 0.9186152 0.9949837 0.7001863 x^2.5 # power ## [1] 1.00000 55.90170 15.58846 498.83063 15.58846 36.15124 x*y # multiplication of vectors of the same size ## a b c d e f ## 0.0 10.0 3.0 108.0 30.0 -4.2 x*1:2 # multiplication of vectors of different sizes ## [1] 1.0 10.0 3.0 24.0 3.0 8.4 x%%2 # modulo ## [1] 1.0 1.0 1.0 0.0 1.0 0.2 x %o% y # outer product of vectors (the result is a matrix) ## a b c d e f ## [1,] 0 2.0 1.0 9.0 10 -1.0 ## [2,] 0 10.0 5.0 45.0 50 -5.0 ## [3,] 0 6.0 3.0 27.0 30 -3.0 ## [4,] 0 24.0 12.0 108.0 120 -12.0 ## [5,] 0 6.0 3.0 27.0 30 -3.0 ## [6,] 0 8.4 4.2 37.8 42 -4.2 3.2.5 Statistics on vectors length(x) # size of vector ## [1] 6 summary(x) # statistics on vector ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.0 3.0 3.6 4.7 4.8 12.0 sum(x) # sum of all terms ## [1] 28.2 mean(x) # average value ## [1] 4.7 median(x) # median value ## [1] 3.6 sd(x) # standard deviation ## [1] 3.823611 table(x) # count occurrence of values ## x ## 1 3 4.2 5 12 ## 1 2 1 1 1 3.2.6 More stuff # cumulative sum cumsum(x) ## [1] 1.0 6.0 9.0 21.0 24.0 28.2 # term-by-term difference diff(x) ## [1] 4.0 -2.0 9.0 -9.0 1.2 # reverse order rev(1:5) ## [1] 5 4 3 2 1 # append values append(x, 4) # at the end ## [1] 1.0 5.0 3.0 12.0 3.0 4.2 4.0 append(x, 4, 3) # or after a given index ## [1] 1.0 5.0 3.0 4.0 12.0 3.0 4.2 # concatenate vectors z &lt;- c(-1:4, NA, -x); z ## [1] -1.0 0.0 1.0 2.0 3.0 4.0 NA -1.0 -5.0 -3.0 -12.0 ## [12] -3.0 -4.2 # find NA values is.na(z); anyNA(z) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE ## [12] FALSE FALSE ## [1] TRUE # remove NA values (operator &quot;!&quot; means &quot;is not&quot;) z &lt;- z[!is.na(z)]; z ## [1] -1.0 0.0 1.0 2.0 3.0 4.0 -1.0 -5.0 -3.0 -12.0 -3.0 ## [12] -4.2 # returns a vector of the indexes verifying the condition z==2; which(z==2) ## [1] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE ## [1] 4 # positive values of z z; z&gt;0; z[z&gt;0]; z[which(z&gt;0)] ## [1] -1.0 0.0 1.0 2.0 3.0 4.0 -1.0 -5.0 -3.0 -12.0 -3.0 ## [12] -4.2 ## [1] FALSE FALSE TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE ## [1] 1 2 3 4 ## [1] 1 2 3 4 3.3 Exercises Exercise 1 Consider two vectors, x, y: x &lt;- 1:5 y &lt;- seq(0, 4, along=x) Without typing it into Rstudio, what are the values of x, y, and x*y? Exercise 2 Consider two vectors, a, b a &lt;- c(1,5,4,3,6) b &lt;- c(3,5,2,1,9) What is the value of: a&lt;=b? Exercise 3 If x &lt;- c(1:12) What is the value of: length(x) Exercise 4 If a &lt;- c(12:5) What is the value of: is.numeric(a) Exercise 5 Consider two vectors, x, y x &lt;- c(12:4) y &lt;- c(0,1,2,0,1,2,0,1,2) What is the value of: which(!is.finite(x/y))? Exercise 6 Consider two vectors, x, y x &lt;- letters[1:10] y &lt;- letters[15:24] What is the value of: x&lt;y? Exercise 7 If x &lt;- c(&#39;blue&#39;,&#39;red&#39;,&#39;green&#39;,&#39;yellow&#39;) What is the value of: is.character(x)? Exercise 8 If x &lt;- c(&#39;blue&#39;,10,&#39;green&#39;,20) What is the value of: is.character(x)? Exercise 9 Assign value 5 to variable x. Is there a difference between 1:x-1 and 1:(x-1) ? Explain. Exercise 10 Generate the sequence 9, 18, 27, 36, 45, 54, 63, 72, 81, 90 in 4 different manners. Exercise 11 If x &lt;- c(&quot;w&quot;, &quot;h&quot;, &quot;f&quot;, &quot;g&quot;, &quot;k&quot;), what will be the output for x[c(2,3)]? “h”, “f” “h” “f” What will be the third value in the index vector operation x[c(2, 4, 4)]? “h” NA “g” What will be the fourth value in the index vector operation x[-2]? “h” “g” “k” Exercise 11 Let a &lt;- c(2, 4, 6, 8) and b &lt;- c(TRUE, FALSE, TRUE, FALSE). What will be the output for the R expression max(a[b])? Exercise 12: Case Application (adapted from here) Open Rstudio and create a new R script, save it as population.R in your wanted directory, say Rcourse/. Download the population.csv file and save it in your working directory. A csv file contains raw data stored as plain text and separated by a comma (Comma Separated Values). Open it from a text editor, as Excel and the likes don’t work well with csv files. We can of course directly load such file with R and store its data in an appropriate format (i.e. a data.frame), but this is for a next section. For now, just copy-paste the text in the Rstudio script area to: Create a cities vector containing all the cities listed in population.csv Create a pop_1962 and pop_2012 vectors containing the populations of each city at these years. Print the 2 vectors. Use names() to name values of pop_1962 and pop_2012. Print the 2 vectors again. Are there any change? What are the cities with more than 200000 people in 1962? For these, how many residents in 2012? What is the population evolution of Montpellier and Nantes? Create a pop_diff vector to store population change between 1962 and 2012 Print cities with a negative change Print cities which broke the 300000 people barrier between 1962 and 2012 Compute the total change in population of the 10 largest cities (as of 1962) between 1962 and 2012. Compute the population mean for year 1962 Compute the population mean of Paris Sort the cities by decreasing order of population for both years Check to see which cities changed rank during these years (check out the match function). Solution # Create a `cities` vector containing all the cities listed in `population.csv` cities &lt;- c(&quot;Angers&quot;, &quot;Bordeaux&quot;, &quot;Brest&quot;, &quot;Dijon&quot;, &quot;Grenoble&quot;, &quot;Le Havre&quot;, &quot;Le Mans&quot;, &quot;Lille&quot;, &quot;Lyon&quot;, &quot;Marseille&quot;, &quot;Montpellier&quot;, &quot;Nantes&quot;, &quot;Nice&quot;, &quot;Paris&quot;, &quot;Reims&quot;, &quot;Rennes&quot;, &quot;Saint-Étienne&quot;, &quot;Strasbourg&quot;, &quot;Toulon&quot;, &quot;Toulouse&quot;) # Create a `pop_1962` and `pop_2012` vectors containing the populations # of each city at these years. Print the 2 vectors. pop_1962 &lt;- c(115273,278403,136104,135694,156707,187845,132181,239955, 535746,778071,118864,240048,292958,2790091,134856,151948, 210311,228971,161797,323724) pop_2012 &lt;- c(149017,241287,139676,152071,158346,173142,143599,228652, 496343,852516,268456,291604,343629,2240621,181893,209860, 171483,274394,164899,453317) pop_1962; pop_2012 ## [1] 115273 278403 136104 135694 156707 187845 132181 239955 ## [9] 535746 778071 118864 240048 292958 2790091 134856 151948 ## [17] 210311 228971 161797 323724 ## [1] 149017 241287 139676 152071 158346 173142 143599 228652 ## [9] 496343 852516 268456 291604 343629 2240621 181893 209860 ## [17] 171483 274394 164899 453317 # Use names() to name values of `pop_1962` and `pop_2012`. # Print the 2 vectors again. Are there any change? names(pop_2012) &lt;- names(pop_1962) &lt;- cities pop_1962; pop_2012 ## Angers Bordeaux Brest Dijon Grenoble ## 115273 278403 136104 135694 156707 ## Le Havre Le Mans Lille Lyon Marseille ## 187845 132181 239955 535746 778071 ## Montpellier Nantes Nice Paris Reims ## 118864 240048 292958 2790091 134856 ## Rennes Saint-Étienne Strasbourg Toulon Toulouse ## 151948 210311 228971 161797 323724 ## Angers Bordeaux Brest Dijon Grenoble ## 149017 241287 139676 152071 158346 ## Le Havre Le Mans Lille Lyon Marseille ## 173142 143599 228652 496343 852516 ## Montpellier Nantes Nice Paris Reims ## 268456 291604 343629 2240621 181893 ## Rennes Saint-Étienne Strasbourg Toulon Toulouse ## 209860 171483 274394 164899 453317 # What are the cities with more than 200000 people in 1962? # For these, how many residents in 2012? cities200k &lt;- cities[pop_1962&gt;200000] cities200k; pop_2012[cities200k] ## [1] &quot;Bordeaux&quot; &quot;Lille&quot; &quot;Lyon&quot; &quot;Marseille&quot; ## [5] &quot;Nantes&quot; &quot;Nice&quot; &quot;Paris&quot; &quot;Saint-Étienne&quot; ## [9] &quot;Strasbourg&quot; &quot;Toulouse&quot; ## Bordeaux Lille Lyon Marseille Nantes ## 241287 228652 496343 852516 291604 ## Nice Paris Saint-Étienne Strasbourg Toulouse ## 343629 2240621 171483 274394 453317 # What is the population evolution of Montpellier and Nantes? pop_2012[&#39;Montpellier&#39;] - pop_1962[&#39;Montpellier&#39;]; pop_2012[&#39;Nantes&#39;] - pop_1962[&#39;Nantes&#39;] ## Montpellier ## 149592 ## Nantes ## 51556 # Create a `pop_diff` vector to store population change between 1962 and 2012 pop_diff &lt;- pop_2012 - pop_1962 # Print cities with a negative change cities[pop_diff&lt;0] ## [1] &quot;Bordeaux&quot; &quot;Le Havre&quot; &quot;Lille&quot; &quot;Lyon&quot; ## [5] &quot;Paris&quot; &quot;Saint-Étienne&quot; # Print cities which broke the 300000 people barrier between 1962 and 2012 cities[pop_2012&gt;300000 &amp; pop_1962&lt;300000] ## [1] &quot;Nice&quot; # Compute the total change in population of the 10 largest cities # (as of 1962) between 1962 and 2012. ten_largest &lt;- cities[order(pop_1962, decreasing = TRUE)[1:10]] sum(pop_2012[ten_largest] - pop_1962[ten_largest]) ## [1] -324432 # Compute the population mean for year 1962 mean(pop_1962) ## [1] 367477.3 # Compute the population mean of Paris mean(c(pop_1962[&#39;Paris&#39;], pop_2012[&#39;Paris&#39;])) ## [1] 2515356 # Sort the cities by decreasing order of population for both years (pop_1962_sorted &lt;- sort(pop_1962, decreasing = TRUE)) ## Paris Marseille Lyon Toulouse Nice ## 2790091 778071 535746 323724 292958 ## Bordeaux Nantes Lille Strasbourg Saint-Étienne ## 278403 240048 239955 228971 210311 ## Le Havre Toulon Grenoble Rennes Brest ## 187845 161797 156707 151948 136104 ## Dijon Reims Le Mans Montpellier Angers ## 135694 134856 132181 118864 115273 (pop_2012_sorted &lt;- sort(pop_2012, decreasing = TRUE)) ## Paris Marseille Lyon Toulouse Nice ## 2240621 852516 496343 453317 343629 ## Nantes Strasbourg Montpellier Bordeaux Lille ## 291604 274394 268456 241287 228652 ## Rennes Reims Le Havre Saint-Étienne Toulon ## 209860 181893 173142 171483 164899 ## Grenoble Dijon Angers Le Mans Brest ## 158346 152071 149017 143599 139676 # Check to see which cities changed rank (and by how much) # during these years (check out the `match` function). ranked_cities &lt;- match(names(pop_1962_sorted),names(pop_2012_sorted)) - seq_along(cities) names(ranked_cities) &lt;- names(pop_1962_sorted) ranked_cities ## Paris Marseille Lyon Toulouse Nice ## 0 0 0 0 0 ## Bordeaux Nantes Lille Strasbourg Saint-Étienne ## 3 -1 2 -2 4 ## Le Havre Toulon Grenoble Rennes Brest ## 2 3 3 -3 5 ## Dijon Reims Le Mans Montpellier Angers ## 1 -5 1 -11 -2 "],
["lists.html", "4 Lists", " 4 Lists Lists allow you to store all types of objects and types of values: booleans, doubles, characters, vectors, other lists, data.frame, etc # initialization L &lt;- list(name = &quot;John&quot;, age = 43, kids = list(name=c(&quot;Kevin&quot;, &quot;Pamela&quot;), # nested list age =c(4,5) ) ) L ## $name ## [1] &quot;John&quot; ## ## $age ## [1] 43 ## ## $kids ## $kids$name ## [1] &quot;Kevin&quot; &quot;Pamela&quot; ## ## $kids$age ## [1] 4 5 # names of entries (can be changed) names(L) ## [1] &quot;name&quot; &quot;age&quot; &quot;kids&quot; # statistics summary(L) ## Length Class Mode ## name 1 -none- character ## age 1 -none- numeric ## kids 2 -none- list # accessing values, with the subtleties L$name # is a vector ## [1] &quot;John&quot; L[&quot;age&quot;];typeof(L[&quot;age&quot;]) # is a list ## $age ## [1] 43 ## [1] &quot;list&quot; L[[&quot;age&quot;]];typeof(L[[&quot;age&quot;]]) # is a vector ## [1] 43 ## [1] &quot;double&quot; L[[3]] # is a list (because &#39;kids&#39; is a list) ## $name ## [1] &quot;Kevin&quot; &quot;Pamela&quot; ## ## $age ## [1] 4 5 L[[3]][&#39;name&#39;] # is a list ## $name ## [1] &quot;Kevin&quot; &quot;Pamela&quot; L[[3]][[&#39;name&#39;]] # is a vector ## [1] &quot;Kevin&quot; &quot;Pamela&quot; # empty initialization LL &lt;- list(); LL # no specific size ## list() LL &lt;- vector(&quot;list&quot;, length=3); LL # specific size ## [[1]] ## NULL ## ## [[2]] ## NULL ## ## [[3]] ## NULL # Concatenation L1 &lt;- list(wife=&quot;Kim&quot;, wife.age=38) L2 &lt;- c(L, L1) typeof(L2); L2 ## [1] &quot;list&quot; ## $name ## [1] &quot;John&quot; ## ## $age ## [1] 43 ## ## $kids ## $kids$name ## [1] &quot;Kevin&quot; &quot;Pamela&quot; ## ## $kids$age ## [1] 4 5 ## ## ## $wife ## [1] &quot;Kim&quot; ## ## $wife.age ## [1] 38 "],
["data-frames.html", "5 Data frames 5.1 Defining a data.frame 5.2 Accessing values 5.3 Adding columns or rows 5.4 More on data.frame 5.5 Exercises", " 5 Data frames 5.1 Defining a data.frame In R, the principal object is the data. Hence the data.frame object, which is basically a table of vectors. A data.frame is a list presented under the form of a table – i.e. a spreadsheet. On a day-to-day basis, you will either define data.frame from existing vectors or other data.frame, or define a data.frame from a file (text, Excel…). In this example, we use test.dat and test.xlsx. # x = 10 random numbers between -10 and 10 x &lt;- runif(10, min=-10, max=10) y &lt;- sin(x) df &lt;- data.frame(x,y) # df is a data.frame (a table) df ## x y ## 1 6.926112 0.59954005 ## 2 6.057758 -0.22352241 ## 3 9.845543 -0.40845870 ## 4 4.330748 -0.92805485 ## 5 -8.354083 -0.87753394 ## 6 -2.227421 -0.79205713 ## 7 -9.905075 0.46204277 ## 8 -3.125155 -0.01643643 ## 9 6.735953 0.43745564 ## 10 3.169628 -0.02803148 # dimension of df dim(df) ## [1] 10 2 # first and last 3 values head(df, 3); tail(df, 3) ## x y ## 1 6.926112 0.5995400 ## 2 6.057758 -0.2235224 ## 3 9.845543 -0.4084587 ## x y ## 8 -3.125155 -0.01643643 ## 9 6.735953 0.43745564 ## 10 3.169628 -0.02803148 # statistics on df summary(df) ## x y ## Min. :-9.905 Min. :-0.9281 ## 1st Qu.:-2.901 1st Qu.:-0.6962 ## Median : 3.750 Median :-0.1258 ## Mean : 1.345 Mean :-0.1775 ## 3rd Qu.: 6.566 3rd Qu.: 0.3240 ## Max. : 9.846 Max. : 0.5995 # changing column name df &lt;- data.frame(xxx=x,yyy=y) head(df,2) ## xxx yyy ## 1 6.926112 0.5995400 ## 2 6.057758 -0.2235224 colnames(df) &lt;- c(&quot;thisISx&quot;,&quot;THISisY&quot;) head(df,2) ## thisISx THISisY ## 1 6.926112 0.5995400 ## 2 6.057758 -0.2235224 # from a matrix A &lt;- matrix(1:9,ncol=3) as.data.frame(A) ## V1 V2 V3 ## 1 1 4 7 ## 2 2 5 8 ## 3 3 6 9 # from a file read.table(&quot;Data/test.dat&quot;) # default column name is V1, V2, V3, etc ## V1 V2 ## 1 x y ## 2 1 2 ## 3 2 3 read.table(&quot;Data/test.dat&quot;,header=TRUE)# use first line as column names ## x y ## 1 1 2 ## 2 2 3 read.table(&quot;Data/test.dat&quot;,skip=1) # skip first line. ## V1 V2 ## 1 1 2 ## 2 2 3 # ?read.table for more options library(openxlsx) # load openxlsx to read Excel files read.xlsx(&quot;Data/test.xlsx&quot;, sheet=1) ## x y ## 1 1 5.2073549 ## 2 2 6.5464871 ## 3 3 3.7056000 ## 4 4 0.2159875 ## 5 5 0.2053786 ## 6 6 4.6029225 ## 7 7 10.2849330 ## 8 8 12.9467912 ## 9 9 11.0605924 ## 10 10 7.2798944 read.xlsx(&quot;Data/test.xlsx&quot;, sheet=2) ## hello world ## 1 ac th ## 2 asc thh ## 3 ascsa dthdh ## 4 ascacs dthtdhdh 5.2 Accessing values # column number df[,1] # this is a vector ## [1] 6.926112 6.057758 9.845543 4.330748 -8.354083 -2.227421 -9.905075 ## [8] -3.125155 6.735953 3.169628 # column name df$thisISx; df[,&quot;THISisY&quot;] # a vector too ## [1] 6.926112 6.057758 9.845543 4.330748 -8.354083 -2.227421 -9.905075 ## [8] -3.125155 6.735953 3.169628 ## [1] 0.59954005 -0.22352241 -0.40845870 -0.92805485 -0.87753394 ## [6] -0.79205713 0.46204277 -0.01643643 0.43745564 -0.02803148 # first row; row 1 to 3 df[1,]; df[1:3,]; ## thisISx THISisY ## 1 6.926112 0.59954 ## thisISx THISisY ## 1 6.926112 0.5995400 ## 2 6.057758 -0.2235224 ## 3 9.845543 -0.4084587 # through conditions df[x&lt;0 &amp; y&gt;0, ] # Here x and y are vectors, not the column names ## thisISx THISisY ## 7 -9.905075 0.4620428 df[ df[,&quot;thisISx&quot;]&lt;0 &amp; df[,2]&gt;0, ] # conditions on columns ## thisISx THISisY ## 7 -9.905075 0.4620428 # subsetting using column names subset(df, thisISx&gt;2 &amp; THISisY&gt;0, select = c(thisISx)) ## thisISx ## 1 6.926112 ## 9 6.735953 5.3 Adding columns or rows # Adding columns df &lt;- data.frame(x,y) df$z &lt;- (df$x)^2; df ## x y z ## 1 6.926112 0.59954005 47.971022 ## 2 6.057758 -0.22352241 36.696438 ## 3 9.845543 -0.40845870 96.934713 ## 4 4.330748 -0.92805485 18.755381 ## 5 -8.354083 -0.87753394 69.790703 ## 6 -2.227421 -0.79205713 4.961405 ## 7 -9.905075 0.46204277 98.110514 ## 8 -3.125155 -0.01643643 9.766597 ## 9 6.735953 0.43745564 45.373057 ## 10 3.169628 -0.02803148 10.046540 data.frame(df,w=1:length(x), xx=NA, yy=1, zz=1:2) ## x y z w xx yy zz ## 1 6.926112 0.59954005 47.971022 1 NA 1 1 ## 2 6.057758 -0.22352241 36.696438 2 NA 1 2 ## 3 9.845543 -0.40845870 96.934713 3 NA 1 1 ## 4 4.330748 -0.92805485 18.755381 4 NA 1 2 ## 5 -8.354083 -0.87753394 69.790703 5 NA 1 1 ## 6 -2.227421 -0.79205713 4.961405 6 NA 1 2 ## 7 -9.905075 0.46204277 98.110514 7 NA 1 1 ## 8 -3.125155 -0.01643643 9.766597 8 NA 1 2 ## 9 6.735953 0.43745564 45.373057 9 NA 1 1 ## 10 3.169628 -0.02803148 10.046540 10 NA 1 2 cbind(df, data.frame(a=1:length(x), b=1:length(x)) ) ## x y z a b ## 1 6.926112 0.59954005 47.971022 1 1 ## 2 6.057758 -0.22352241 36.696438 2 2 ## 3 9.845543 -0.40845870 96.934713 3 3 ## 4 4.330748 -0.92805485 18.755381 4 4 ## 5 -8.354083 -0.87753394 69.790703 5 5 ## 6 -2.227421 -0.79205713 4.961405 6 6 ## 7 -9.905075 0.46204277 98.110514 7 7 ## 8 -3.125155 -0.01643643 9.766597 8 8 ## 9 6.735953 0.43745564 45.373057 9 9 ## 10 3.169628 -0.02803148 10.046540 10 10 # Adding rows rbind(df, df) # with a data.frame ## x y z ## 1 6.926112 0.59954005 47.971022 ## 2 6.057758 -0.22352241 36.696438 ## 3 9.845543 -0.40845870 96.934713 ## 4 4.330748 -0.92805485 18.755381 ## 5 -8.354083 -0.87753394 69.790703 ## 6 -2.227421 -0.79205713 4.961405 ## 7 -9.905075 0.46204277 98.110514 ## 8 -3.125155 -0.01643643 9.766597 ## 9 6.735953 0.43745564 45.373057 ## 10 3.169628 -0.02803148 10.046540 ## 11 6.926112 0.59954005 47.971022 ## 12 6.057758 -0.22352241 36.696438 ## 13 9.845543 -0.40845870 96.934713 ## 14 4.330748 -0.92805485 18.755381 ## 15 -8.354083 -0.87753394 69.790703 ## 16 -2.227421 -0.79205713 4.961405 ## 17 -9.905075 0.46204277 98.110514 ## 18 -3.125155 -0.01643643 9.766597 ## 19 6.735953 0.43745564 45.373057 ## 20 3.169628 -0.02803148 10.046540 rbind(df, df[1,]) # with a vector ## x y z ## 1 6.926112 0.59954005 47.971022 ## 2 6.057758 -0.22352241 36.696438 ## 3 9.845543 -0.40845870 96.934713 ## 4 4.330748 -0.92805485 18.755381 ## 5 -8.354083 -0.87753394 69.790703 ## 6 -2.227421 -0.79205713 4.961405 ## 7 -9.905075 0.46204277 98.110514 ## 8 -3.125155 -0.01643643 9.766597 ## 9 6.735953 0.43745564 45.373057 ## 10 3.169628 -0.02803148 10.046540 ## 11 6.926112 0.59954005 47.971022 # deleting rows/columns df[-1,] ## x y z ## 2 6.057758 -0.22352241 36.696438 ## 3 9.845543 -0.40845870 96.934713 ## 4 4.330748 -0.92805485 18.755381 ## 5 -8.354083 -0.87753394 69.790703 ## 6 -2.227421 -0.79205713 4.961405 ## 7 -9.905075 0.46204277 98.110514 ## 8 -3.125155 -0.01643643 9.766597 ## 9 6.735953 0.43745564 45.373057 ## 10 3.169628 -0.02803148 10.046540 df[,-1] ## y z ## 1 0.59954005 47.971022 ## 2 -0.22352241 36.696438 ## 3 -0.40845870 96.934713 ## 4 -0.92805485 18.755381 ## 5 -0.87753394 69.790703 ## 6 -0.79205713 4.961405 ## 7 0.46204277 98.110514 ## 8 -0.01643643 9.766597 ## 9 0.43745564 45.373057 ## 10 -0.02803148 10.046540 5.4 More on data.frame 5.4.1 More math operations Almost everything that we saw on the operations on vectors are basically applicable to the data.frame object. 5.4.2 Tidy up! A good practice in R is to tidy your data. R follows a set of conventions that makes one layout of tabular data much easier to work with than others. Your data will be easier to work with in R if it follows three rules: Each variable in the data set is placed in its own column Each observation is placed in its own row Each value is placed in its own cell Data that satisfies these rules is known as tidy data. Example: df &lt;- read.csv(&quot;Data/population.csv&quot;) df # is not tidy Show output ## Année Angers Bordeaux Brest Dijon Grenoble Le.Havre Le.Mans Lille ## 1 1962 115273 278403 136104 135694 156707 187845 132181 239955 ## 2 1968 128557 266662 154023 145357 161616 207150 143246 238554 ## 3 1975 137591 223131 166826 151705 166037 217882 152285 219204 ## 4 1982 136038 208159 156060 140942 156637 199388 147697 196705 ## 5 1990 141404 210336 147956 146703 150758 195854 145502 198691 ## 6 1999 151279 215363 149634 149867 153317 190905 146105 212597 ## 7 2007 151108 235178 142722 151543 156793 179751 144164 225789 ## 8 2012 149017 241287 139676 152071 158346 173142 143599 228652 ## Lyon Marseille Montpellier Nantes Nice Paris Reims Rennes ## 1 535746 778071 118864 240048 292958 2790091 134856 151948 ## 2 527800 889029 161910 260244 322442 2590771 154534 180943 ## 3 456716 908600 191354 256693 344481 2299830 178381 198305 ## 4 413095 874436 197231 240539 337085 2176243 177234 194656 ## 5 415487 800550 207996 244995 342439 2152423 180620 197536 ## 6 445452 798430 225392 270251 342738 2125246 187206 206229 ## 7 472330 852395 253712 283025 348721 2193030 183500 207922 ## 8 496343 852516 268456 291604 343629 2240621 181893 209860 ## Saint.Étienne Strasbourg Toulon Toulouse ## 1 210311 228971 161797 323724 ## 2 223223 249396 174746 370796 ## 3 220181 253384 181801 373796 ## 4 204955 248712 179423 347995 ## 5 199396 252338 167619 358688 ## 6 180210 264115 160639 390350 ## 7 175318 272123 166537 439453 ## 8 171483 274394 164899 453317 library(tidyr) df &lt;- gather(df, names(df)[-1], key=&quot;city&quot;, value=&quot;pop&quot;) df #is tidy Show output ## Année city pop ## 1 1962 Angers 115273 ## 2 1968 Angers 128557 ## 3 1975 Angers 137591 ## 4 1982 Angers 136038 ## 5 1990 Angers 141404 ## 6 1999 Angers 151279 ## 7 2007 Angers 151108 ## 8 2012 Angers 149017 ## 9 1962 Bordeaux 278403 ## 10 1968 Bordeaux 266662 ## 11 1975 Bordeaux 223131 ## 12 1982 Bordeaux 208159 ## 13 1990 Bordeaux 210336 ## 14 1999 Bordeaux 215363 ## 15 2007 Bordeaux 235178 ## 16 2012 Bordeaux 241287 ## 17 1962 Brest 136104 ## 18 1968 Brest 154023 ## 19 1975 Brest 166826 ## 20 1982 Brest 156060 ## 21 1990 Brest 147956 ## 22 1999 Brest 149634 ## 23 2007 Brest 142722 ## 24 2012 Brest 139676 ## 25 1962 Dijon 135694 ## 26 1968 Dijon 145357 ## 27 1975 Dijon 151705 ## 28 1982 Dijon 140942 ## 29 1990 Dijon 146703 ## 30 1999 Dijon 149867 ## 31 2007 Dijon 151543 ## 32 2012 Dijon 152071 ## 33 1962 Grenoble 156707 ## 34 1968 Grenoble 161616 ## 35 1975 Grenoble 166037 ## 36 1982 Grenoble 156637 ## 37 1990 Grenoble 150758 ## 38 1999 Grenoble 153317 ## 39 2007 Grenoble 156793 ## 40 2012 Grenoble 158346 ## 41 1962 Le.Havre 187845 ## 42 1968 Le.Havre 207150 ## 43 1975 Le.Havre 217882 ## 44 1982 Le.Havre 199388 ## 45 1990 Le.Havre 195854 ## 46 1999 Le.Havre 190905 ## 47 2007 Le.Havre 179751 ## 48 2012 Le.Havre 173142 ## 49 1962 Le.Mans 132181 ## 50 1968 Le.Mans 143246 ## 51 1975 Le.Mans 152285 ## 52 1982 Le.Mans 147697 ## 53 1990 Le.Mans 145502 ## 54 1999 Le.Mans 146105 ## 55 2007 Le.Mans 144164 ## 56 2012 Le.Mans 143599 ## 57 1962 Lille 239955 ## 58 1968 Lille 238554 ## 59 1975 Lille 219204 ## 60 1982 Lille 196705 ## 61 1990 Lille 198691 ## 62 1999 Lille 212597 ## 63 2007 Lille 225789 ## 64 2012 Lille 228652 ## 65 1962 Lyon 535746 ## 66 1968 Lyon 527800 ## 67 1975 Lyon 456716 ## 68 1982 Lyon 413095 ## 69 1990 Lyon 415487 ## 70 1999 Lyon 445452 ## 71 2007 Lyon 472330 ## 72 2012 Lyon 496343 ## 73 1962 Marseille 778071 ## 74 1968 Marseille 889029 ## 75 1975 Marseille 908600 ## 76 1982 Marseille 874436 ## 77 1990 Marseille 800550 ## 78 1999 Marseille 798430 ## 79 2007 Marseille 852395 ## 80 2012 Marseille 852516 ## 81 1962 Montpellier 118864 ## 82 1968 Montpellier 161910 ## 83 1975 Montpellier 191354 ## 84 1982 Montpellier 197231 ## 85 1990 Montpellier 207996 ## 86 1999 Montpellier 225392 ## 87 2007 Montpellier 253712 ## 88 2012 Montpellier 268456 ## 89 1962 Nantes 240048 ## 90 1968 Nantes 260244 ## 91 1975 Nantes 256693 ## 92 1982 Nantes 240539 ## 93 1990 Nantes 244995 ## 94 1999 Nantes 270251 ## 95 2007 Nantes 283025 ## 96 2012 Nantes 291604 ## 97 1962 Nice 292958 ## 98 1968 Nice 322442 ## 99 1975 Nice 344481 ## 100 1982 Nice 337085 ## 101 1990 Nice 342439 ## 102 1999 Nice 342738 ## 103 2007 Nice 348721 ## 104 2012 Nice 343629 ## 105 1962 Paris 2790091 ## 106 1968 Paris 2590771 ## 107 1975 Paris 2299830 ## 108 1982 Paris 2176243 ## 109 1990 Paris 2152423 ## 110 1999 Paris 2125246 ## 111 2007 Paris 2193030 ## 112 2012 Paris 2240621 ## 113 1962 Reims 134856 ## 114 1968 Reims 154534 ## 115 1975 Reims 178381 ## 116 1982 Reims 177234 ## 117 1990 Reims 180620 ## 118 1999 Reims 187206 ## 119 2007 Reims 183500 ## 120 2012 Reims 181893 ## 121 1962 Rennes 151948 ## 122 1968 Rennes 180943 ## 123 1975 Rennes 198305 ## 124 1982 Rennes 194656 ## 125 1990 Rennes 197536 ## 126 1999 Rennes 206229 ## 127 2007 Rennes 207922 ## 128 2012 Rennes 209860 ## 129 1962 Saint.Étienne 210311 ## 130 1968 Saint.Étienne 223223 ## 131 1975 Saint.Étienne 220181 ## 132 1982 Saint.Étienne 204955 ## 133 1990 Saint.Étienne 199396 ## 134 1999 Saint.Étienne 180210 ## 135 2007 Saint.Étienne 175318 ## 136 2012 Saint.Étienne 171483 ## 137 1962 Strasbourg 228971 ## 138 1968 Strasbourg 249396 ## 139 1975 Strasbourg 253384 ## 140 1982 Strasbourg 248712 ## 141 1990 Strasbourg 252338 ## 142 1999 Strasbourg 264115 ## 143 2007 Strasbourg 272123 ## 144 2012 Strasbourg 274394 ## 145 1962 Toulon 161797 ## 146 1968 Toulon 174746 ## 147 1975 Toulon 181801 ## 148 1982 Toulon 179423 ## 149 1990 Toulon 167619 ## 150 1999 Toulon 160639 ## 151 2007 Toulon 166537 ## 152 2012 Toulon 164899 ## 153 1962 Toulouse 323724 ## 154 1968 Toulouse 370796 ## 155 1975 Toulouse 373796 ## 156 1982 Toulouse 347995 ## 157 1990 Toulouse 358688 ## 158 1999 Toulouse 390350 ## 159 2007 Toulouse 439453 ## 160 2012 Toulouse 453317 spread(df, city, pop) # is not tidy Show output ## Année Angers Bordeaux Brest Dijon Grenoble Le.Havre Le.Mans Lille ## 1 1962 115273 278403 136104 135694 156707 187845 132181 239955 ## 2 1968 128557 266662 154023 145357 161616 207150 143246 238554 ## 3 1975 137591 223131 166826 151705 166037 217882 152285 219204 ## 4 1982 136038 208159 156060 140942 156637 199388 147697 196705 ## 5 1990 141404 210336 147956 146703 150758 195854 145502 198691 ## 6 1999 151279 215363 149634 149867 153317 190905 146105 212597 ## 7 2007 151108 235178 142722 151543 156793 179751 144164 225789 ## 8 2012 149017 241287 139676 152071 158346 173142 143599 228652 ## Lyon Marseille Montpellier Nantes Nice Paris Reims Rennes ## 1 535746 778071 118864 240048 292958 2790091 134856 151948 ## 2 527800 889029 161910 260244 322442 2590771 154534 180943 ## 3 456716 908600 191354 256693 344481 2299830 178381 198305 ## 4 413095 874436 197231 240539 337085 2176243 177234 194656 ## 5 415487 800550 207996 244995 342439 2152423 180620 197536 ## 6 445452 798430 225392 270251 342738 2125246 187206 206229 ## 7 472330 852395 253712 283025 348721 2193030 183500 207922 ## 8 496343 852516 268456 291604 343629 2240621 181893 209860 ## Saint.Étienne Strasbourg Toulon Toulouse ## 1 210311 228971 161797 323724 ## 2 223223 249396 174746 370796 ## 3 220181 253384 181801 373796 ## 4 204955 248712 179423 347995 ## 5 199396 252338 167619 358688 ## 6 180210 264115 160639 390350 ## 7 175318 272123 166537 439453 ## 8 171483 274394 164899 453317 You can find more information on data import and tidyness on the data-import cheatsheet. 5.4.3 Tibbles A tibble is an enhanced version of the data.frame provided by the tidyverse package. The main advantage of tibble is that it shows better performance than data.frame for large datasets, and it has easier initialization and nicer printing. Otherwise, the handling is basically the same. More on tibbles here. library(tidyverse) ## ── Attaching packages ────────────────────────────────── tidyverse 1.2.1 ── ## ✔ tibble 2.0.1 ✔ dplyr 0.8.0.1 ## ✔ readr 1.3.1 ✔ stringr 1.4.0 ## ✔ purrr 0.3.2 ✔ forcats 0.4.0 ## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks plotly::filter(), stats::filter() ## ✖ dplyr::lag() masks stats::lag() tibble(x=runif(1e3), y=cumsum(x)) ## # A tibble: 1,000 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.193 0.193 ## 2 0.831 1.02 ## 3 0.710 1.73 ## 4 0.829 2.56 ## 5 0.294 2.86 ## 6 0.867 3.72 ## 7 0.133 3.86 ## 8 0.791 4.65 ## 9 0.928 5.58 ## 10 0.421 6.00 ## # … with 990 more rows data.frame(x=runif(1e3), y=cumsum(x)) ## Error in data.frame(x = runif(1000), y = cumsum(x)): object &#39;x&#39; not found 5.5 Exercises Exercise 1 Create a 3 column data.frame containing 100 random values, their sinus, and the sum of the two first columns. Do the same with a tibble Exercise 2 Download population.txt and load it into a data.frame. Are the data tidy? What are the names of the columns? Create a subset containing the data for Montpellier What is the max and min of population in this city? The average population over time? What is the total population in 2012? Solution # Download [population.txt](Data/population.txt) and load it into a `data.frame`. popul &lt;- read.table(&quot;Data/population.txt&quot;, header=TRUE) # Are the data tidy? head(popul) ## year city pop ## 1 1962 Angers 115273 ## 2 1968 Angers 128557 ## 3 1975 Angers 137591 ## 4 1982 Angers 136038 ## 5 1990 Angers 141404 ## 6 1999 Angers 151279 # What are the names of the columns and the dimension of the table? names(popul); dim(popul) ## [1] &quot;year&quot; &quot;city&quot; &quot;pop&quot; ## [1] 160 3 # Create a subset containing the data for Montpellier mtp &lt;- subset(popul, city==&quot;Montpellier&quot;) # What is the max and min of population in this city? range(mtp[,&quot;pop&quot;]) ## [1] 118864 268456 # The average population over time? mean(mtp[,&quot;pop&quot;]) ## [1] 203114.4 # What is the total population in 2012? sum(popul[popul[,&quot;year&quot;]==2012, &quot;pop&quot;]) ## [1] 7334805 "],
["functions.html", "6 Functions 6.1 Definition 6.2 Exercises", " 6 Functions 6.1 Definition To get the manual on a base function, type ?function_name. A function returns the last thing that is called in it: geom_mean &lt;- function(x, y){ a &lt;- sqrt(x*y) } geom_mean(1,2) #returns nothing geom_mean &lt;- function(x, y){ a &lt;- sqrt(x*y) a } geom_mean(1,2) #returns a ## [1] 1.414214 One can add default values to variables: testfunc &lt;- function(x,y=1){ x*y } testfunc(1) ## [1] 1 testfunc(1,y=2) ## [1] 2 testfunc(1:3,y=.1) ## [1] 0.1 0.2 0.3 And pass arguments to other functions: testfunc2 &lt;- function(x,...){ head(x,...) } testfunc2(1:100) ## [1] 1 2 3 4 5 6 testfunc2(1:100,2) ## [1] 1 2 Or even pass a function as argument: testfunc3 &lt;- function(FUN,...){ FUN(...) } testfunc3(sum,1:10) ## [1] 55 testfunc3(plot, 1:10, sin(1:10), type=&quot;l&quot;) 6.2 Exercises Exercise 1 Write a function returning a list (created if empty, incremented if existing) containing the name, age and gender of the people in the class. Use it to print the list as a list or as a data.frame. Solution people &lt;- function(ppl=list(), name, age, gender){ # if the list is not provided, initialize it if(length(ppl)==0) ppl &lt;- list() # increment vectors ppl[[&#39;name&#39;]] &lt;- c(ppl[[&#39;name&#39;]], name) ppl[[&#39;age&#39;]] &lt;- c(ppl[[&#39;age&#39;]], age) ppl[[&#39;gender&#39;]] &lt;- c(ppl[[&#39;gender&#39;]], gender) # return the list ppl } ppl &lt;- people(name=&quot;Colin&quot;, age=33, gender=&quot;Male&quot;) ppl &lt;- people(ppl=ppl, name=&quot;Vincent&quot;, age=39, gender=&quot;Male&quot;) ppl ## $name ## [1] &quot;Colin&quot; &quot;Vincent&quot; ## ## $age ## [1] 33 39 ## ## $gender ## [1] &quot;Male&quot; &quot;Male&quot; as.data.frame(ppl) ## name age gender ## 1 Colin 33 Male ## 2 Vincent 39 Male Exercise 2 Create the sinus cardinal function, \\(f(x)=\\sin(x)/x\\) for \\(x\\neq0\\) and \\(f(0)=1\\). Solution sinc &lt;- function(x){ # sinus cardinal y &lt;- rep(1,length(x)) b &lt;- which(x!=0) y[b] &lt;- sin(x[b])/x[b] y } sinc(seq(-pi,pi,pi/4)) ## [1] 3.898172e-17 3.001054e-01 6.366198e-01 9.003163e-01 1.000000e+00 ## [6] 9.003163e-01 6.366198e-01 3.001054e-01 3.898172e-17 x &lt;- seq(-8*pi,8*pi,.1) plot(x, sinc(x), type=&quot;l&quot;, lwd=3);abline(h=0,v=0) "],
["conditional-actions-and-loops.html", "7 Conditional actions and loops 7.1 Conditional actions 7.2 Loops… 7.3 … and how to avoid them 7.4 Exercises", " 7 Conditional actions and loops 7.1 Conditional actions Conditional actions in R can be determined through the usual if then else statements: x &lt;- 1; y &lt;- 2 if(x&gt;y){ print(&quot;x is larger than y&quot;) }else if(x&lt;y){ print(&quot;x is smaller than y&quot;) }else{ print(&quot;x is equal to y&quot;) } ## [1] &quot;x is smaller than y&quot; # if else in on line x &lt;- rnorm(5, mean=5) ifelse(x&gt;5, &quot;larger than 5&quot;, &quot;lower than 5&quot;) ## [1] &quot;larger than 5&quot; &quot;larger than 5&quot; &quot;lower than 5&quot; &quot;lower than 5&quot; ## [5] &quot;larger than 5&quot; 7.2 Loops… Loops in R are provided through the usual for and while keywords: # For loop for(i in 1:100){ # pass to next index directly if(i %in% c(3,8,5)) next # break loop if(i==10) break print(i) } ## [1] 1 ## [1] 2 ## [1] 4 ## [1] 6 ## [1] 7 ## [1] 9 phrase &lt;- c(&quot;hello&quot;, &quot;world&quot;) for(word in phrase){ print(word) } ## [1] &quot;hello&quot; ## [1] &quot;world&quot; # While loop i &lt;- 1 while(i&lt;8){ print(i) i &lt;- i+2 } ## [1] 1 ## [1] 3 ## [1] 5 ## [1] 7 7.3 … and how to avoid them However, since R is a vectorized language, it means that loops are to be avoided when possible because they are very inefficient: test_time &lt;- function(FUN,...) { start_time &lt;- Sys.time() FUN(...) elapsed_time &lt;- Sys.time()-start_time print(paste(&quot;Elapsed time :&quot;, elapsed_time, &quot;s - &quot;, as.character(substitute(FUN))) ) } forloop &lt;- function(x){ for(i in seq_along(x)){ x[i] &lt;- 2*x[i] } x } noforloop &lt;- function(x){ 2*x } x &lt;- runif(1e8) test_time(forloop, x); test_time(noforloop, x) ## [1] &quot;Elapsed time : 6.76087403297424 s - forloop&quot; ## [1] &quot;Elapsed time : 0.495260953903198 s - noforloop&quot; Avoiding loops should therefore be though for when possible. R helps us in this way through the base functions apply, sapply and lapply. Take a look at the help on these functions, but the summary is that apply(df, direction, function) applies a function in the wanted direction (1 for rows, 2 for columns) of the given data.frame (or vector). Example: library(tidyverse) dt &lt;- tibble(x=1:5, y=x^2, z=x^3);dt ## # A tibble: 5 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 ## 2 2 4 8 ## 3 3 9 27 ## 4 4 16 64 ## 5 5 25 125 apply(dt, 1, mean) # mean of the rows ## [1] 1.000000 4.666667 13.000000 28.000000 51.666667 apply(dt, 2, mean) # mean of the columns ## x y z ## 3 11 45 lapply (and equivalently, sapply) is basically the same thing but applied to lists and it returns a list (a vector): my_list &lt;- list(dt/3, dt/5);my_list ## [[1]] ## x y z ## 1 0.3333333 0.3333333 0.3333333 ## 2 0.6666667 1.3333333 2.6666667 ## 3 1.0000000 3.0000000 9.0000000 ## 4 1.3333333 5.3333333 21.3333333 ## 5 1.6666667 8.3333333 41.6666667 ## ## [[2]] ## x y z ## 1 0.2 0.2 0.2 ## 2 0.4 0.8 1.6 ## 3 0.6 1.8 5.4 ## 4 0.8 3.2 12.8 ## 5 1.0 5.0 25.0 lapply(my_list, &quot;[&quot;, 1, ) # print first row ## [[1]] ## x y z ## 1 0.3333333 0.3333333 0.3333333 ## ## [[2]] ## x y z ## 1 0.2 0.2 0.2 sapply(my_list, rowSums) # sum on rows ## [,1] [,2] ## [1,] 1.000000 0.6 ## [2,] 4.666667 2.8 ## [3,] 13.000000 7.8 ## [4,] 28.000000 16.8 ## [5,] 51.666667 31.0 lapply(my_list, round, 1) # round to first decimal ## [[1]] ## x y z ## 1 0.3 0.3 0.3 ## 2 0.7 1.3 2.7 ## 3 1.0 3.0 9.0 ## 4 1.3 5.3 21.3 ## 5 1.7 8.3 41.7 ## ## [[2]] ## x y z ## 1 0.2 0.2 0.2 ## 2 0.4 0.8 1.6 ## 3 0.6 1.8 5.4 ## 4 0.8 3.2 12.8 ## 5 1.0 5.0 25.0 # For more complex operations, use it this way: sapply(1:nrow(dt), function(i){ dt$x[i] + dt$y[(i+2)%%nrow(dt)+1] - dt$z[(i+4)%%nrow(dt)+1] }) ## [1] 16 19 -23 -56 -111 7.4 Exercises Exercise 1 Given x &lt;- runif(1e3, min=-1, max=1), create a tibble like this one: ## # A tibble: 1,000 x 2 ## x y ## &lt;dbl&gt; &lt;chr&gt; ## 1 0.208 x&gt;0 ## 2 -0.700 x&lt;=0 ## 3 0.630 x&gt;0 ## 4 0.563 x&gt;0 ## 5 -0.980 x&lt;=0 ## 6 0.721 x&gt;0 ## 7 0.0670 x&gt;0 ## 8 0.207 x&gt;0 ## 9 -0.321 x&lt;=0 ## 10 0.899 x&gt;0 ## # … with 990 more rows Exercise 2 Given: LL &lt;- list(A = runif(1e2), B = rnorm(1e3), C = data.frame(x=runif(1e2), y=runif(1e2)) ) Print the sum of each element of LL in a list, in a vector. Solution LL &lt;- list(A = runif(1e2), B = rnorm(1e3), C = data.frame(x=runif(1e2), y=runif(1e2)) ) lapply(LL, sum) ## $A ## [1] 47.91722 ## ## $B ## [1] 15.40265 ## ## $C ## [1] 101.5066 unlist(lapply(LL, sum)); sapply(LL, sum) ## A B C ## 47.91722 15.40265 101.50664 ## A B C ## 47.91722 15.40265 101.50664 Exercise 3 Download population.csv and load it into a data.frame What is the total population over the years? What is the mean population for each city? Solution # Download [population.csv](Data/population.csv) and load it into a `data.frame` df &lt;- read.csv(&quot;Data/population.csv&quot;) # What is the total population over the years? data.frame(year=df[,&quot;Année&quot;], pop =rowSums(df[,-1]), # a first way pop2=apply(df[,-1], 1, sum)# another way ) ## year pop pop2 ## 1 1962 7349547 7349547 ## 2 1968 7550999 7550999 ## 3 1975 7298183 7298183 ## 4 1982 6933230 6933230 ## 5 1990 6857291 6857291 ## 6 1999 6965325 6965325 ## 7 2007 7235114 7235114 ## 8 2012 7334805 7334805 # A tidy-compatible version popul &lt;- gather(df, names(df)[-1], key=&quot;city&quot;, value=&quot;pop&quot;) popul %&gt;% group_by(Année) %&gt;% summarise(totpop = sum(pop)) ## # A tibble: 8 x 2 ## Année totpop ## &lt;int&gt; &lt;int&gt; ## 1 1962 7349547 ## 2 1968 7550999 ## 3 1975 7298183 ## 4 1982 6933230 ## 5 1990 6857291 ## 6 1999 6965325 ## 7 2007 7235114 ## 8 2012 7334805 # or equivalently summarise(group_by(popul, Année), totpop = sum(pop)) ## # A tibble: 8 x 2 ## Année totpop ## &lt;int&gt; &lt;int&gt; ## 1 1962 7349547 ## 2 1968 7550999 ## 3 1975 7298183 ## 4 1982 6933230 ## 5 1990 6857291 ## 6 1999 6965325 ## 7 2007 7235114 ## 8 2012 7334805 # What is the mean population for each city? apply(df[,-1], 2, mean) ## Angers Bordeaux Brest Dijon Grenoble ## 138783.4 234814.9 149125.1 146735.2 157526.4 ## Le.Havre Le.Mans Lille Lyon Marseille ## 193989.6 144347.4 220018.4 470371.1 844253.4 ## Montpellier Nantes Nice Paris Reims ## 203114.4 260924.9 334311.6 2321031.9 172278.0 ## Rennes Saint.Étienne Strasbourg Toulon Toulouse ## 193424.9 198134.6 255429.1 169682.6 382264.9 summarise(group_by(popul, city), totpop = mean(pop)) ## # A tibble: 20 x 2 ## city totpop ## &lt;chr&gt; &lt;dbl&gt; ## 1 Angers 138783. ## 2 Bordeaux 234815. ## 3 Brest 149125. ## 4 Dijon 146735. ## 5 Grenoble 157526. ## 6 Le.Havre 193990. ## 7 Le.Mans 144347. ## 8 Lille 220018. ## 9 Lyon 470371. ## 10 Marseille 844253. ## 11 Montpellier 203114. ## 12 Nantes 260925. ## 13 Nice 334312. ## 14 Paris 2321032. ## 15 Reims 172278 ## 16 Rennes 193425. ## 17 Saint.Étienne 198135. ## 18 Strasbourg 255429. ## 19 Toulon 169683. ## 20 Toulouse 382265. "],
["plotting.html", "8 Plotting 8.1 Base graphics 8.2 Advanced plotting using ggplot2 8.3 3D color plots 8.4 Exercises", " 8 Plotting Now that we have seen most of the basics, let’s start the fun stuff ! There are two main ways to plot data in R: Using base graphics, the native R plotting device Using the package ggplot2 and tidy data frames ggplot2 is extremely powerful and some people advise not even teaching base graphics to beginners. But I find that some times it’s just quicker/easier with base graphics, so I will still present it, although not in full details. 8.1 Base graphics 8.1.1 Basic plotting x &lt;- seq(-3*pi,3*pi,length=1000) y &lt;- sinc(x) z &lt;- sinc(x)^2 df &lt;- data.frame(x=x, y=y) plot(x,y) # plot providing x and y data plot(df) # plot providing a two-columns data.frame df &lt;- data.frame(x=x, y=y, z=z, w=z*y) plot(df) # plot providing a multi-columns data.frame 8.1.2 Adding some style OK, easy. Now let’s do some tuning of this, because it’s a tad ugly… Type in each command and see what they do. # create some fake data x &lt;- seq(-3*pi,3*pi,length=100) df &lt;- data.frame(x=x, y=sinc(x), z=sinc(x)^2) # add some styling parameters par(family = &quot;Helvetica&quot;, cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, 2, .5), lwd=2, las=1) plot(df$x,df$y, type = &quot;l&quot;, # &quot;l&quot; for lines, &quot;p&quot; for points xlab = &quot;X values&quot;, ylab = &quot;Intensity&quot;, axes = FALSE, main = &quot;Some Plot&quot; ) # vertical line in 0 abline(v=0,lty=2,lwd=2) # horizontal line in 0 abline(h=0,lty=3,lwd=2) # line with coefficients a (intercept) and b (slope) abline(a=0,b=.1,lty=4,lwd=1) # add a line lines(df$x,df$z,type = &quot;l&quot;,col=&quot;red&quot;,lwd=3) # add points points(df$x,df$z*df$y,col=&quot;royalblue&quot;,pch=16,cex=1) # add custom axis. # Default with axis(1);axis(2);axis(3, labels=FALSE);axis(4, labels=FALSE); # Bottom axis(1,at=seq(-10,10,2),labels=TRUE,tck=0.02) axis(1,at=seq(-10,10,1),labels=FALSE,tck=0.01); # small inter-ticks # Top axis(3,at=seq(-10,10,2),labels=FALSE) axis(3,at=seq(-10,10,1),labels=FALSE,tck=0.01); # small inter-ticks # Left axis(2,at=seq(-1,1,.2),labels=TRUE) axis(2,at=seq(-1,1,.1),labels=FALSE,tck=0.01); # small inter-ticks # Right axis(4,at=seq(-1,1,.2),labels=FALSE) axis(4,at=seq(-1,1,.1),labels=FALSE,tck=0.01); # small inter-ticks # Draw a box box() # Print legend legend(&quot;topleft&quot;, cex=1.4, #size of text lty=c(1,1,NA), # type of line (1 is full, 2 is dashed...) lwd=c(1,3,NA), # line width pch=c(NA,NA,16), # type of points col=c(&quot;black&quot;,&quot;red&quot;,&quot;royalblue&quot;), # color bty = &quot;n&quot;, # no box around legend legend=c(&quot;sinc(x)&quot;,expression(&quot;sinc(x)&quot;^2),expression(&quot;sinc(x)&quot;^3)) ) Most needs should be covered with this simple plot that can be adapted. A plot can be exported if surrounded by XXX and dev.off(), with XXX that can be pdf(&quot;xxx.pdf&quot;,height=6, width=8), png(&quot;xxx.png&quot;,height=6, width=8)… Example: pdf(&quot;test.pdf&quot;,height=6, width=8) plot(x,y, type=&quot;l&quot;, xlab=&quot;x&quot; ) dev.off() You can also export the graph as a .tex file using tikz, which allows you to use \\(\\LaTeX\\) mathematical expressions (don’t forget to escape the \\ character): library(tikzDevice) tikz(&quot;plot.tex&quot;,height=6, width=8,pointsize = 10,standAlone=TRUE) plot(x,y, type=&quot;l&quot;, xlab=&quot;\\\\omega_i&quot; ) dev.off() 8.1.3 Going further 8.1.3.1 Panel plots Lets create a plot with different panels (a bit ugly without styling, you need to tweak the margins and text distance to plot with par(mar(), mgp()) before each plot): # some fake data x &lt;- seq(-10,10,1) d1 &lt;- data.frame(x=x, y=sin(x)) d2 &lt;- data.frame(x=x, y=sinc(x)) d3 &lt;- data.frame(x=x, y=exp(-x^2)*sinc(x)^2) # creating the layout and styling M &lt;- matrix(c(c(1,1),c(2,3)), byrow=TRUE, ncol=2); M ## [,1] [,2] ## [1,] 1 1 ## [2,] 2 3 nf &lt;- layout(M, heights=c(1), widths=c(1)) # first plot plot(d1,type=&quot;l&quot;) # second plot plot(d2,type=&quot;p&quot;) # third plot plot(d3,type=&quot;b&quot;) # creating the layout and styling M &lt;- matrix(c(c(1,1),c(2,3)), byrow=FALSE, ncol=2); M ## [,1] [,2] ## [1,] 1 2 ## [2,] 1 3 nf &lt;- layout(M, heights=c(1), widths=c(1)) # first plot plot(d1,type=&quot;l&quot;) # second plot plot(d2,type=&quot;p&quot;) # third plot plot(d3,type=&quot;b&quot;) 8.1.3.2 Barplots and densities x &lt;- rnorm(1e4, mean = 0, sd = 1) # Barplot hist(x) # Density y &lt;- density(x, bw=0.1) # small kernel bandwidth y2 &lt;- density(x, bw=0.5) # larger kernel bandwidth plot(y, lwd=2, main=&quot;&quot;, xlab=&quot;X values&quot;, xlim=c(-4,4)) lines(y2,col=&quot;red&quot;,lwd=2) points(x, jitter(rep(.01,length(x)), amount=.01), cex=1,pch=16, col=adjustcolor(&quot;royalblue&quot;, alpha=.01)) 8.2 Advanced plotting using ggplot2 Further (more detailed) readings here and on the cheatsheet for example. ggplot2 is a package (now even available for python) that completely changes the methodology of plotting data. With ggplot2, data are gathered in a tidy data.frame, and each column can be used as a parameter to tweak colors, point size, etc. First things first, load the library: library(ggplot2) 8.2.1 A quick plot A quick plot can be made using the function qplot (for “quickplot”), very similar to the base graphics plot function. It’s great for allowing you to produce plots quickly, but it is highly recommended learning ggplot() as it makes it easier to create complex graphics. Note how different is the default theme of the plot: # some fake data x &lt;- seq(-10,10,.5) y &lt;- sinc(x) p1 &lt;- qplot(x,y, geom=&quot;line&quot;) # ggplot2 quick plot p2 &lt;- qplot(x,y, geom=&quot;point&quot;) # ggplot2 quick plot p1; p2 ## ## Attaching package: &#39;cowplot&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## ggsave 8.2.2 The grammar of graphics With ggplot2 is introduced the notion of “grammar of graphics” through the function ggplot(). What it means is that the plots are built through independent blocks that can be combined to create any wanted graphical display. To construct a plot, you need to provide building blocks such as: data gathered in a tidy data.frame an aesthetics mapping: what column is x, y, the color, the size, etc… geometric object: points, lines, bars… statistical transformations scales coordinate system position adjustments faceting Since a figure is worth a thousand words, let’s get to it. We will use the dataset diamonds built-in with the ggplot2 package. Let’s have a look: diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # … with 53,930 more rows diamonds contains 53940 lines and 10 columns in a tibble (which is basically a data.frame with more advanced properties, let’s not get into it for now). ggplot can easily handle such large dataset. Let’s say we want to see whether there is a correlation between price and weight (carat) of the diamonds: p &lt;- ggplot(data=diamonds,aes(x=carat,y=price)) p + geom_point() OK, we’re onto something, but we can probably add some information to this plot. We will first cut the data above 3 carats because they are not relevant, and add some transparency to the points to see some statistical information. p &lt;- ggplot(data=subset(diamonds, carat&lt;=3), mapping=aes(x=carat,y=price)) p + geom_point(alpha=0.1) Let’s now see whether the clarity plays a role here by coloring the points according to the diamonds cut: p &lt;- ggplot(data=subset(diamonds, carat&lt;=3), mapping=aes(x=carat,y=price, color=cut)) p + geom_point(alpha=0.1) It looks like the price dispersion is homogeneous, we can make sure by adding a spline smoothing: p + geom_point(alpha=0.1) + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; The slope evolution shows that in general, the better the cut, the higher the price. But there are some discrepancies that may be explained in another manner: p &lt;- ggplot(data=subset(diamonds, carat&lt;=3), mapping=aes(x=carat,y=price, color=clarity)) p + geom_point(alpha=0.1) + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; It is often easier to grasp a multi-variable problem by plotting all our data in a facet plot using facet_wrap() colors &lt;- rainbow(length(unique(diamonds$clarity))) p &lt;- ggplot(diamonds, aes(x=price,y=carat)) + geom_point(aes(color=clarity), alpha=0.5, size=1) + geom_smooth(color=&quot;black&quot;) + scale_colour_manual(values = colors, name=&quot;Clarity&quot;) + facet_wrap(~cut) p ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; Or by adding another graphical parameter such as the size of the points: p &lt;- ggplot(diamonds, aes(x=price,y=carat, size=cut)) + geom_point(aes(color=clarity), alpha=0.5) + scale_colour_manual(values = colors, name=&quot;Clarity&quot;) p OK, maybe not here because the graph gets clogged, so we can lighten it by sampling data: p &lt;- ggplot(diamonds[sample(1:dim(diamonds)[1], size=500),], aes(x=carat,y=price, size=cut)) + geom_point(aes(color=clarity), alpha=0.5) + scale_colour_manual(values = colors, name=&quot;Clarity&quot;) p 8.2.3 Theming It is very easy to keep the same theme on all your graphs thanks to the theme function. There are a collection of pre-defined themes, like: p + theme_grey() # the default p + theme_classic() p + theme_bw() p + theme_minimal() p + theme_dark() p + theme_light() You can define all the parameters you want, like this (hit ?theme like usual to see all the parameters): my_theme &lt;- theme_bw()+ theme(axis.text = element_text(size = 14,family = &quot;Helvetica&quot;,colour=&quot;black&quot;), text = element_text(size = 14,family = &quot;Helvetica&quot;), axis.ticks = element_line(colour = &quot;black&quot;), legend.text = element_text(size = 14,family = &quot;Helvetica&quot;,colour=&quot;black&quot;), panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size=1), legend.key.height=unit(0.5,&quot;cm&quot;) ) p + my_theme 8.2.4 Making interactive plots with ggplot2 and plotly Thanks to the plotly package, it is really easy to transform a ggplot plot into an interactive plot: # load plotly library(plotly) p &lt;- ggplot(diamonds[sample(1:dim(diamonds)[1], size=100),], aes(x=carat,y=price)) + geom_point(aes(color=clarity), alpha=0.5, size=2) + my_theme ggplotly(p) 8.2.5 Gathering plots on a grid If you have several plot you want to gather on a grid and you can’t use facet_wrap (because they come from different data sets), you can use the library cowplot and its function plot_grid(): library(cowplot) p1 &lt;- qplot(1:10, sin(1:10)) p2 &lt;- qplot(1:10, cos(1:10)) p3 &lt;- qplot(1:10, tan(1:10)) theme_set(theme_grey()) # to keep the theme_grey plot_grid(p1, p2, p3, labels=c(&quot;a)&quot;,&quot;b)&quot;,&quot;c)&quot;), ncol=3) 8.3 3D color plots You may want to plot your data as a color map, like the evolution of a Raman spectrum as a function of temperature, pressure or position. In some cases you’ll have a 3-columns data.frame with x, y, and z values (e.g. intensity of a peak as a function of the position on the sample), in some cases you can have a list of spectra evolving with a given parameter. 8.3.1 The ggplot2 solution Let’s create a dummy set of spectra that we will gather in a tidy tibble. Nspec &lt;- 40 # Amount of spectra T &lt;- seq(273, 500, length=Nspec) # Fake Temperatures N &lt;- 500 # Size of the x vector library(tidyverse) fake_data &lt;- tibble() # Empty tibble (for performance) for (i in 1:Nspec) { # Let&#39;s create dummy x and y values # You would normally use a read.table here x &lt;- seq(0, 100, length = N) y &lt;- 50*dnorm(x, mean= (T[i]/T[1])*20 + 25, sd = 10+runif(1,max=5) ) fake_data &lt;- rbind(fake_data, tibble(w=x, Intensity=y, T=T[i]) ) } fake_data ## # A tibble: 20,000 x 3 ## w Intensity T ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0.00304 273 ## 2 0.200 0.00321 273 ## 3 0.401 0.00339 273 ## 4 0.601 0.00358 273 ## 5 0.802 0.00379 273 ## 6 1.00 0.00400 273 ## 7 1.20 0.00422 273 ## 8 1.40 0.00446 273 ## 9 1.60 0.00470 273 ## 10 1.80 0.00496 273 ## # … with 19,990 more rows OK, so now we have some fake experimental data stored in a tidy tibble called fake_data. We want to plot it as a color map in order to grasp the evolution of the spectra: # Plotting P1 &lt;- ggplot(data=fake_data, aes(x=w, y=T, fill=Intensity)) + geom_raster() + #geom_tile would work to ggtitle(&quot;Some fake data&quot;) + scale_fill_gradientn(colors=colorRampPalette(c(&quot;white&quot;,&quot;royalblue&quot;,&quot;seagreen&quot;,&quot;orange&quot;,&quot;red&quot;,&quot;brown&quot;))(500),name=&quot;Intensity\\n[arb. units]&quot;) + labs(x = &quot;Fake Raman Shift [1/cm]&quot;,y=&quot;Fake Temperature [K]&quot;) + theme_bw() ggplotly(P1) # Some other way : a stacking of plots fake_data$offset &lt;- norm01(fake_data$Intensity) + rep(1:length(T)-1, each=length(x)) colors &lt;- colorRampPalette(c(&quot;royalblue&quot;,&quot;seagreen&quot;,&quot;orange&quot;,&quot;red&quot;,&quot;brown&quot;))(Nspec) P2 &lt;- ggplot(data=fake_data, aes(x=w, y=offset, color=T, group=T)) + geom_line() + labs(x=&quot;Fake Raman Shift [1/cm]&quot;, y=&quot;Fake Intensity [arb. units]&quot;) + scale_color_gradientn(colors=colors) + coord_cartesian(xlim = c(25,75)) + theme_bw() ggplotly(P2) 8.3.2 The base graphics solution In some cases you end up with a matrix z, and two vectors x and y. This is easy to plot using the base image function. For the sake of example, let’s just use the acast function on our melted 3-columns data.frame: library(reshape2) z &lt;- acast(data.frame(fake_data), x~T, value.var=&quot;Intensity&quot;) x &lt;- unique(data.frame(fake_data)[,&quot;w&quot;]) y &lt;- unique(data.frame(fake_data)[,&quot;T&quot;]) x &lt;- x[order(x)] y &lt;- y[order(y)] colors &lt;- colorRampPalette(c(&quot;white&quot;,&quot;royalblue&quot;,&quot;seagreen&quot;,&quot;orange&quot;,&quot;red&quot;,&quot;brown&quot;))(500) par(mar=c(4, 4, .5, 4), lwd=2) image(x,y,z,col = colors) You can add a legend by using the image.plot function: library(fields) par(mar=c(4, 4, .5, 4), lwd=2) image.plot(x,y,z, col = colors) 8.3.3 The plotly solution And finally, if you want to make this an interactive plot, you can use plotly: library(plotly) aX &lt;- list(title = &quot;Raman Shift [1/cm]&quot;) aY &lt;- list(title = &quot;Temperature [K]&quot;) # Weird but you need to use t(z) here: z &lt;- t(z) # Color plot plot_ly(x=x,y=y,z=z,type = &quot;heatmap&quot;,colors=colors) %&gt;% layout(xaxis = aX, yaxis = aY) Or, very cool, an interactive surface plot: plot_ly(x=x,y=y,z=z,type = &quot;surface&quot;,colors=colors) %&gt;% layout(scene = list(xaxis = aX, yaxis = aY, dragmode=&quot;turntable&quot;)) 8.3.4 2D density of points In case you want to plot a density of points, you have a variety of solutions: df &lt;- tibble(x=rnorm(1e3, mean=c(1,5)), y=rnorm(1e3, mean=c(5,1))) p1 &lt;- ggplot(data=df, aes(x=x,y=y))+ geom_density2d() + ggtitle(&#39;geom_density2d()&#39;) p2 &lt;- ggplot(data=df, aes(x=x,y=y))+ geom_hex() + ggtitle(&#39;geom_hex()&#39;) p3 &lt;- ggplot(data=df, aes(x=x,y=y))+ geom_bin2d() + ggtitle(&#39;geom_bin2d()&#39;) p4 &lt;- ggplot(data=df, aes(x=x,y=y))+ ggtitle(&#39;stat_density2d()&#39;) + stat_density2d(aes(fill = ..density..), geom = &quot;tile&quot;, contour = FALSE, n = 200) + scale_fill_continuous(low = &quot;white&quot;, high = &quot;dodgerblue4&quot;) library(cowplot) plot_grid(p1,p2,p3,p4) Or the base smoothScatter() function could do the trick: smoothScatter(df) 8.4 Exercises Exercise 1 Download the two sample Raman spectra: PPC60_G_01.txt and PPC60_G_30.txt Load them in two separate data.frame Plot them together using base graphics, one in red lines, one in blue points Is the y axis alright? correct it if needed Add the corresponding legend where you see fit (e.g. top left corner) Create a function norm01 to normalize data to [0,1] Do the same plot with data normalized to [0,1] Play with the theme to reproduce the following plot: Gather the two data.frame in a single tidy one, and do an equivalent plot in ggplot2 What are the difficulties you encountered in each case (base graphics and ggplot)? You now see that each graphics has its perks and downsides. Solution # Load them in two separate `data.frame` df1 &lt;- read.table(&quot;Data/PPC60_G_01.txt&quot;, col.names=c(&quot;w&quot;,&quot;Int&quot;)) df2 &lt;- read.table(&quot;Data/PPC60_G_30.txt&quot;, col.names=c(&quot;w&quot;,&quot;Int&quot;)) norm01 &lt;- function(x) {(x-min(x))/(max(x)-min(x))} # Plot them together using base graphics, one in red lines, one in blue points par(family = &quot;Times&quot;, cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, .5, .5), lwd=2, las=1) plot(df1$w, norm01(df1$Int), xlab=&quot;Raman Shift [1/cm]&quot;, ylab=&quot;Intensity [arb. unit]&quot;, type=&quot;l&quot;, col=&quot;red&quot;, ylim=c(0,1), lwd=3) points(df2$w, norm01(df2$Int), col=&quot;royalblue&quot;, pch=16, cex=1) axis(3, labels=FALSE) axis(4, labels=FALSE) legend(&quot;topleft&quot;, cex=1.4, lty=c(1, NA), lwd=c(3, NA), pch=c(NA, 16), col=c(&quot;red&quot;, &quot;royalblue&quot;), bty = &quot;n&quot;, legend=c(&quot;PPC60_G_01&quot;, &quot;PPC60_G_30&quot;) ) # Gather them in a single tidy `data.frame`, and do the same in `ggplot2` df1$name &lt;- &quot;PPC60_G_01&quot; df1$norm &lt;- norm01(df1$Int) df2$name &lt;- &quot;PPC60_G_30&quot; df2$norm &lt;- norm01(df2$Int) df &lt;- rbind(df1, df2) ggplot(df, aes(x=w, y=norm)) + geom_line(data=subset(df, name==&quot;PPC60_G_01&quot;), size=1, aes(color=name))+ geom_point(data=subset(df, name==&quot;PPC60_G_30&quot;), size=2, aes(color=name))+ scale_color_manual(values=c(&quot;red&quot;,&quot;royalblue&quot;), name=&quot;&quot;) + labs(x=&quot;Raman Shift [1/cm]&quot;, y=&quot;Intensity [arb. unit]&quot;) + theme_bw() + theme(legend.position = c(0.1,.9), text = element_text(size = 16,family = &quot;Times&quot;), axis.text = element_text(size = 16), legend.text = element_text(size = 14)) Exercise 2 Using df &lt;- data.frame(x=rnorm(1e4), y=rnorm(1e4)), try reproducing the following plots using ggplot2: ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Exercise 3 Download population.csv and load it into a data.frame Is it a tidy data.frame? Do we want a tidy data.frame? Why? Act accordingly Plot the population vs. year with a color for each city With points With lines With a black and white theme Change the axis labels to “Year” and “Population” Make it interactive Try reproducing the following plots (Google is your friend): Solution # Load and tidy population data.frame df &lt;- read.csv(&quot;Data/population.csv&quot;) library(tidyr) df &lt;- gather(df, names(df)[-1], key=&quot;City&quot;, value=&quot;Population&quot;) names(df)[1] &lt;- &quot;Year&quot; # Plot the population vs. year with a different color for each city p &lt;- ggplot(data=df, aes(x=Year, y=Population, color=City)) # With points p + geom_point() # With lines p + geom_line() # With a black and white theme # Change the axis labels to &quot;Year&quot; and &quot;Population&quot; p &lt;- p + geom_line() + theme_bw() + xlab(&quot;Year&quot;) + ylab(&quot;Population&quot;); p # Make it interactive library(plotly) ggplotly(p) # Reproduce the plots my_theme &lt;- theme_bw()+ theme(axis.text = element_text(size = 14,family = &quot;Helvetica&quot;,colour=&quot;black&quot;), text = element_text(size = 14,family = &quot;Helvetica&quot;), axis.ticks = element_line(colour = &quot;black&quot;), legend.text = element_text(size = 10,family = &quot;Helvetica&quot;,colour=&quot;black&quot;), panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size=1) ) colors &lt;- c(&quot;royalblue&quot;,&quot;red&quot;) p1 &lt;- ggplot(data=subset(df,City%in%c(&quot;Montpellier&quot;,&quot;Nantes&quot;)), aes(x=Year, y=Population, size=Population, color=City)) + geom_point() + scale_color_manual(values=colors)+ ggtitle(&quot;Population in Montpellier and Nantes&quot;)+ labs(x=&quot;Year&quot;, y=&quot;Population&quot;)+ my_theme p1 p2 &lt;- ggplot(data=subset(df,Year==2012), aes(x=reorder(City,-Population), y=Population/1e6, fill=Population/1e6)) + geom_bar(stat=&quot;identity&quot;, position=&quot;dodge&quot;) + ggtitle(&quot;Population in 2012 (in millions)&quot;)+ labs(x=&quot;&quot;, y=&quot;Population (in millions)&quot;)+ scale_fill_gradientn(colors=colors, name=&quot;Population\\n(in millions)&quot;) + my_theme + theme(axis.text.x = element_text(angle = 45, hjust=1)) p2 p3 &lt;- ggplot(data=subset(df,Year&lt;2000), aes(x=City, y=Population/1e6, fill=City)) + geom_bar(stat=&quot;identity&quot;) + facet_wrap(~Year) + scale_x_discrete(labels = &quot;&quot;) + my_theme + labs(x = &quot;&quot;, y=&quot;Population (in millions)&quot;) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), strip.background = element_blank(), legend.key.height = unit(1,&quot;line&quot;), legend.key.size = unit(1,&quot;line&quot;) ) p3 "],
["fitting.html", "9 Fitting 9.1 Linear fitting 9.2 Non linear fitting 9.3 Exercises", " 9 Fitting 9.1 Linear fitting Let’s learn how to do simple fits with R and plot the results. # Create some fake data d &lt;- read.table(header=TRUE,text=&quot; x y 39.11 6.67 46.1 10.8 52.02 16.36 56.07 23.16 61.00 26.5 65.26 31.3 69.16 33.5 74.00 41.0 81.70 50.3 &quot;) # Fit with a linear model fit &lt;- lm(y~x, data=d) # Summary of the fit summary(fit) ## ## Call: ## lm(formula = y ~ x, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0747 -0.9575 -0.2466 1.1052 2.1321 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -35.85628 2.50588 -14.31 1.94e-06 *** ## x 1.03284 0.04052 25.49 3.65e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.562 on 7 degrees of freedom ## Multiple R-squared: 0.9893, Adjusted R-squared: 0.9878 ## F-statistic: 649.7 on 1 and 7 DF, p-value: 3.655e-08 attributes(fit) ## $names ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; &quot;model&quot; ## ## $class ## [1] &quot;lm&quot; # Retrieve the coefficients and errors coef(fit); coef(fit)[1]; coef(fit)[&#39;(Intercept)&#39;] ## (Intercept) x ## -35.856284 1.032836 ## (Intercept) ## -35.85628 ## (Intercept) ## -35.85628 summary(fit)$coefficients; summary(fit)$coefficients[&quot;x&quot;,&quot;Std. Error&quot;] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -35.856284 2.50587890 -14.30887 1.936873e-06 ## x 1.032836 0.04052143 25.48863 3.654832e-08 ## [1] 0.04052143 # Plotting the points and the fit par(cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, .5, .5), lwd=2, las=1) plot(d, pch=16) abline(coef(fit), col=&quot;red&quot;) to_print &lt;- paste(&quot;y = &quot;, round(coef(fit)[1],2),&quot; + x*&quot;, round(coef(fit)[2],2), sep=&quot;&quot;) text(50, 50, to_print) ggplot(data=d, aes(x,y)) + geom_point(cex=3) + geom_smooth(method=&quot;lm&quot;) + annotate(&quot;text&quot;, x = 50, y = 50, label = to_print) The function geom_smooth() will fit the data and display the fitted line, but to retrieve the actual coefficients you still need to run lm(). 9.2 Non linear fitting You can fit data with your own functions and constraints using nsl. Example: 9.2.1 Base R # Create fake data x &lt;- seq(-7,7,.1) y &lt;- dnorm(x, sd = .5) + dnorm(x, mean=2, sd = 1) + runif(length(x))/10 df &lt;- data.frame(x=x,y=y) # Create a function to fit the data myfunc &lt;- function(x, y0, x0, A, B) { y0 + dnorm(x, sd=A) + dnorm(x, mean=x0, sd=B) } # Fit the data using a user function fit &lt;- nls(y ~ myfunc(x, y0, x0, A, B), data=df, start=list(y0=0, x0=1.5, A=.2, B=.2) # provide starting point ) summary(fit) ## ## Formula: y ~ myfunc(x, y0, x0, A, B) ## ## Parameters: ## Estimate Std. Error t value Pr(&gt;|t|) ## y0 0.047380 0.002416 19.61 &lt;2e-16 *** ## x0 1.980732 0.022766 87.00 &lt;2e-16 *** ## A 0.497010 0.007090 70.11 &lt;2e-16 *** ## B 0.960872 0.019047 50.45 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.02869 on 137 degrees of freedom ## ## Number of iterations to convergence: 8 ## Achieved convergence tolerance: 1.555e-06 x0 &lt;- coef(fit)[&quot;x0&quot;]; y0 &lt;- coef(fit)[&quot;y0&quot;] A &lt;- coef(fit)[&quot;A&quot;]; B &lt;- coef(fit)[&quot;B&quot;] # Plotting the resulting function in red par(cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, .5, .5), lwd=2, las=1) plot(x, y, pch=16, ylim=c(0,1.1)) lines(x, myfunc(x, y0, x0, A, B), col=&quot;red&quot;, lwd=2) Or with ggplot2: ggplot(data=df, aes(x,y))+ geom_point() + geom_smooth(method = &quot;nls&quot;, method.args = list(formula = y ~ myfunc(x, y0, x0, A, B), start=list(y0=0, x0=1.5, A=.2, B=.2) ), data = df, se = FALSE, color=&quot;red&quot;) In nls it is even possible to constraint the fitting by adding lower and upper boundaries. You have to be careful with these and not provide stupid ones, e.g.: # Constraining the upper and lower values of the fitting parameters fit2 &lt;- nls(y~ myfunc(x, y0, x0, A, B), start=list(y0=0, x0=5, A=.2, B=.2), upper=list(y0=Inf, x0=Inf, A=.4, B=1), lower=list(y0=-Inf, x0=4, A=-Inf, B=-Inf), algorithm = &quot;port&quot; ) x0 &lt;- coef(fit2)[&quot;x0&quot;]; y0 &lt;- coef(fit2)[&quot;y0&quot;] A &lt;- coef(fit2)[&quot;A&quot;]; B &lt;- coef(fit2)[&quot;B&quot;] # Plotting the resulting function in blue par(cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, 2, .5), lwd=2, las=1) plot(x, y, pch=16, ylim=c(0,1.1), main=&quot;Beware of constraints&quot;) lines(x, myfunc(x, y0, x0, A, B), col=&quot;royalblue&quot;, lwd=2) 9.2.2 FME Some times though, whatever the initial conditions of the fit you use, you will get the error message Error in nlsModel(formula, mf, start, wts) : singular gradient matrix at initial parameter estimates. If playing around with the initial parameters does not solve this problem, a more robust fitting method is needed. A good one is modFit() from the package FME, that also accepts constraints. With modFit, the algorithm minimizes the residual of the observed data minus the model, so the syntax is slightly different: library(FME) ## Loading required package: deSolve ## Loading required package: rootSolve ## Loading required package: coda myfunc &lt;- function(x, params) { parms &lt;- as.list(params) parms$y0 + dnorm(x, sd=parms$A) + dnorm(x, mean=parms$x0, sd=parms$B) } params &lt;- c(y0=0, x0=5, A=.2, B=.2) # initial guess ModCost &lt;- function(P) { return(y - myfunc(x, P)) # residuals } fit &lt;- modFit(f = ModCost, p = params) summary(fit) ## ## Parameters: ## Estimate Std. Error t value Pr(&gt;|t|) ## y0 0.047380 0.002416 19.61 &lt;2e-16 *** ## x0 1.980731 0.022766 87.00 &lt;2e-16 *** ## A 0.497010 0.007090 70.11 &lt;2e-16 *** ## B 0.960872 0.019047 50.45 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.02869 on 137 degrees of freedom ## ## Parameter correlation: ## y0 x0 A B ## y0 1.000e+00 2.542e-07 2.458e-07 1.094e-06 ## x0 2.542e-07 1.000e+00 3.423e-02 7.552e-03 ## A 2.458e-07 3.423e-02 1.000e+00 2.206e-01 ## B 1.094e-06 7.552e-03 2.206e-01 1.000e+00 par(cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, 2, .5), lwd=2, las=1) plot(x, y, pch=16, ylim=c(0,1.1), main=&quot;FME::modFit&quot;) lines(x, myfunc(x,fit$par), col=&quot;royalblue&quot;, lwd=2) 9.3 Exercises Exercise 1 Load exo_fit.txt in a data.frame. Using lm or nls fit each column as a function of x and display the “experimental” data and the fit on the same graph. Tip: Take a look at the function dnorm to define a Gaussian Exercise 2: application to real data Load the Raman spectrum rubis_1.txt, normalize it to [0,1] and plot it Define the Lorentzian function Create a function that is the sum of 2 Lorentzians Guess grossly the initial parameters and plot the resulting curve Fit the data by a sum of 2 Lorentzians using nls Try playing with the starting parameters to get rid of the error Define a function returning the sum of Lorentzians taking the parameters as a vector, sumLor(x, params). Define the ModCost function returning the residuals of the fit Use the same initial parameters as before and plot the initial guessed curve Fit the data using FME::modFit() What happens with the y0 parameter? use a constraint to keep the parameters plausible Plot the resulting fit Solution # Load [PPC60_G_01.txt](Data/PPC60_G_01.txt) and plot it d &lt;- read.table(&quot;Data/rubis_1.txt&quot;, header=FALSE, col.names=c(&quot;w&quot;, &quot;Int&quot;)) ## Warning in file(file, &quot;rt&quot;): cannot open file &#39;Data/rubis_1.txt&#39;: No such ## file or directory ## Error in file(file, &quot;rt&quot;): cannot open the connection norm01 &lt;- function(x) {(x-min(x))/(max(x)-min(x))} d$Int_n &lt;- norm01(d$Int) ## Warning in min(x): no non-missing arguments to min; returning Inf ## Warning in max(x): no non-missing arguments to max; returning -Inf ## Warning in min(x): no non-missing arguments to min; returning Inf ## Error in `$&lt;-.data.frame`(`*tmp*`, Int_n, value = numeric(0)): replacement has 0 rows, data has 9 par(cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, 2, .5), lwd=2, las=1) plot(d$w, d$Int_n) ## Warning in min(x): no non-missing arguments to min; returning Inf ## Warning in max(x): no non-missing arguments to max; returning -Inf ## Warning in min(x): no non-missing arguments to min; returning Inf ## Warning in max(x): no non-missing arguments to max; returning -Inf ## Error in plot.window(...): need finite &#39;xlim&#39; values # Define the Lorentzian function Lorentzian &lt;- function(x,x0=0,FWHM=1,A=1,y0=0){ y0 + 2*A/(pi*FWHM)/( 1 + ((x-x0)/(FWHM/2))^2 ) } # Create a function that is the sum of 2 Lorentzians Lor2 &lt;- function(x,x1,FWHM1,A1,y1,x2,FWHM2,A2,y2){ Lorentzian(x,x0=x1,FWHM=FWHM1,A=A1,y0=y1) + Lorentzian(x,x0=x2,FWHM=FWHM2,A=A2,y0=y2) } # Guess grossly the initial parameters and plot the resulting curve lines(d$w,Lor2(d$w,x1=3160, FWHM1=10, A1=3, y1=0.03, x2=3200, FWHM2=10, A2=7, y2=0), col=&quot;red&quot;) # Fit the data by a sum of 2 Lorentzians using `nls` fit &lt;- nls(data=d, Int_n ~ Lor2(w,x1,FWHM1,A1,y1,x2,FWHM2,A2,y2), start=list(x1=3160, FWHM1=10, A1=3, y1=0.03, x2=3200, FWHM2=10, A2=7, y2=0) ) ## Error in nls(data = d, Int_n ~ Lor2(w, x1, FWHM1, A1, y1, x2, FWHM2, A2, : parameters without starting value in &#39;data&#39;: Int_n, w # This doesn&#39;t work... we need to use a more robust fitting method # Define a function returning the sum of two Lorentzians # taking the parameters as a vector, `sumLor(x, params)` sumLor &lt;- function(x,params){ # sum of Lorentzian functions y0 &lt;- as.numeric(params[grep(&quot;y0&quot;,names(params))]) A &lt;- as.numeric(params[grep(&quot;A&quot;,names(params))]) x0 &lt;- as.numeric(params[grep(&quot;x0&quot;,names(params))]) FWHM &lt;- as.numeric(params[grep(&quot;FWHM&quot;,names(params))]) if(length(x0)!=length(FWHM)) FWHM &lt;- rep(FWHM, length.out=length(x0)) if(length(x0)!=length(A)) A &lt;- rep(A, length.out=length(x0)) if(length(x0)!=length(y0)) y0 &lt;- rep(y0, length.out=length(x0)) rowSums(sapply(1:length(x0), function(i) { y0[i] + 2*A[i]/(pi*FWHM[i])/( 1 + ((x-x0[i])/(FWHM[i]/2))^2 ) })) } # Define the `ModCost` function returning the residuals of the fit ModCost &lt;- function(P) {d$Int_n - sumLor(d$w, P)} # Use the same initial parameters as before and plot the initial guessed curve params &lt;- c(x0=c(3160, 3200), FWHM=c(10,10), A=c(3,7), y0=c(0.01,0.01)) par(cex.lab=1.5, cex.axis=1.4, mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, 2, .5), lwd=2, las=1) plot(d$w, d$Int_n, pch=16, col=adjustcolor(&quot;black&quot;, alpha=.5), cex=1) ## Warning in min(x): no non-missing arguments to min; returning Inf ## Warning in min(x): no non-missing arguments to max; returning -Inf ## Warning in min(x): no non-missing arguments to min; returning Inf ## Warning in max(x): no non-missing arguments to max; returning -Inf ## Error in plot.window(...): need finite &#39;xlim&#39; values lines(d$w, sumLor(d$w, params), col=&quot;blue&quot;) ## Error in base::rowSums(x, na.rm = na.rm, dims = dims, ...): &#39;x&#39; must be an array of at least two dimensions # Fit the data using `FME::modFit()` # What happens on the `y0` parameter? use a constraint to keep the parameters plausible library(FME) fit &lt;- modFit(f=ModCost, p=params, lower=c(x0=c(0,0), A=c(0,0), FWHM=c(0,0),y0=c(0,0))) ## Error in base::rowSums(x, na.rm = na.rm, dims = dims, ...): &#39;x&#39; must be an array of at least two dimensions # Plot the resulting fit lines(d$w, sumLor(d$w, coef(fit)), col=&quot;red&quot;) ## Error in base::rowSums(x, na.rm = na.rm, dims = dims, ...): &#39;x&#39; must be an array of at least two dimensions "],
["practical-case-recursive-data-treatment.html", "10 Practical case: recursive data treatment", " 10 Practical case: recursive data treatment Here I will provide an example workflow for treating large amounts of experimental measurements. There are many ways of doing this, this is just a working example. You will find here the corresponding experimental data. My way of doing things – again, maybe not the best, but it’s what I do – is that for each experiment I create a folder containing at least 4 objects: log.Rmd: the markdown or R notebook in which I treat the data. I can produce a pdf or html document from it. We will see about that in the next section. myfunc.R: my user-defined functions that I can load in my working environment using source(myfunc.R) Data/: folder containing the original data (usually ASCII files) that I never modify (reproducible data treatment and all that) Plots/: folder containing the static (pdf) plots produced with log.Rmd So, let’s begin. First we set up our working environment: # Set the working directory setwd(&quot;/Users/colin/Travail/Enseignements/R/&quot;) # and load the user-defined functions source(&quot;myfunc.R&quot;) In the working directory, we create a folder Data in which we extract the XP_data.zip archive. It contains a number of txt files named rubis_XX.txt. They are Raman spectra of ruby chips under pressure used for the calibration of pressure in a diamond anvil cell, their shift is directly correlated to the pressure in the DAC. First, let’s list all these files: # Find all the files in &quot;Data&quot; frubis &lt;- list.files(path=&quot;Data&quot;, pattern = &quot;rubis&quot;) head(frubis) ## [1] &quot;rubis_01.txt&quot; &quot;rubis_02.txt&quot; &quot;rubis_03.txt&quot; &quot;rubis_04.txt&quot; ## [5] &quot;rubis_05.txt&quot; &quot;rubis_06.txt&quot; length(frubis) ## [1] 17 # Create a tibble to store each spectra library(tidyverse) spec &lt;- tibble() # and a data.frame to store the fit parameters fitpar &lt;- data.frame() Now let’s read the data, store them in the tibble spec together with other informations, such as the name of the file, the fitted curves of the peaks, or the obtained pressure (the function Pruby() is defined in myfunc.R). # Reading and storing all treated data for(i in seq_along(frubis)){#i &lt;- 1 # Reading raw data d &lt;- read.table(file.path(&quot;Data&quot;,frubis[i]),sep=&quot;\\t&quot;) names(d) &lt;- c(&quot;w&quot;, &quot;Int&quot;) # Fitting two Lorentzians using the previously defined functions # sumLor is defined in &quot;myfunc.R&quot; # Initial guess of the position and parameters: xmax &lt;- d$w[which.max(d$Int)] params &lt;- c(x0=c(xmax, xmax-30), FWHM=c(10,10), A=c(3,7), y0=c(0.01,0.01)) # Fit the data ModCost &lt;- function(param) {d$Int - sumLor(d$w, param)} fit &lt;- modFit(f=ModCost, p=params, lower=c(x0 =c(0,0), A =c(0,0), FWHM=c(0,0), y0 =c(0,0)) ) # Compute the various components of the fit y1 &lt;- sumLor(d$w, c(x0=coef(fit)[&#39;x01&#39;], FWHM=coef(fit)[&#39;FWHM1&#39;], A=coef(fit)[&#39;A1&#39;], y0=coef(fit)[&#39;y01&#39;])) y2 &lt;- sumLor(d$w, c(x0=coef(fit)[&#39;x02&#39;], FWHM=coef(fit)[&#39;FWHM2&#39;], A=coef(fit)[&#39;A2&#39;], y0=coef(fit)[&#39;y02&#39;])) ytot &lt;- y1+y2 # Store all the data and fits in a tidy tibble spec &lt;- rbind(spec, tibble(w = d$w, Int = d$Int, Int_n = d$Int/max(d$Int), y1 = y1, y1_n = y1/max(d$Int), y2 = y2, y2_n = y2/max(d$Int), ytot = ytot, ytot_n = ytot/max(d$Int), name = gsub(&quot;.txt&quot;,&quot;&quot;,frubis[i]), P = round(Pruby(coef(fit)[&#39;x01&#39;]),2) ) ) # Store the fitting parameters in a tidy data.frame fitpar &lt;- rbind(fitpar, data.frame(param=names(coef(fit)), fit=coef(fit), name=gsub(&quot;.txt&quot;,&quot;&quot;,frubis[i]), P=round(Pruby(coef(fit)[&#39;x01&#39;]),2) ) ) # Uncomment and plot to check if everything is OK: # j &lt;- i # ggplot(data=subset(spec, name==gsub(&quot;.txt&quot;,&quot;&quot;,frubis[j])),aes(x=w)) + # ggtitle(gsub(&quot;.txt&quot;,&quot;&quot;,frubis[j]))+ # geom_point(aes(w,Int))+ # geom_line(aes(w,ytot),color=&quot;red&quot;)+ # geom_area(aes(w,y1),fill=&quot;orange&quot;, alpha=0.1)+ # geom_area(aes(w,y2),fill=&quot;royalblue&quot;, alpha=0.1)+ # theme_bw() } Now let’s take a global look at our data. For this I like the slider functionality of plotly. Make your ggplot as usual, and just add the keyword frame that is read by ggplotly(): gg &lt;- ggplot(data=spec,aes(x=w)) + labs(x=&quot;Raman Shift [1/cm]&quot;, y=&quot;Intensity [arb. units]&quot;)+ geom_point(aes(x=w, y=Int_n, frame=P))+ geom_line(aes(x=w,y=ytot_n, frame=P),color=&quot;red&quot;)+ geom_line(aes(x=w,y=y1_n, frame=P),color=&quot;royalblue&quot;, alpha=0.5)+ geom_line(aes(x=w,y=y2_n, frame=P),color=&quot;orange&quot;, alpha=0.5)+ theme_bw() ggplotly(gg) %&gt;% animation_opts(5)%&gt;% animation_slider( currentvalue = list(prefix = &quot;Pressure: &quot;, suffix = &quot; GPa&quot;, font = list(color=&quot;red&quot;)) ) In case you want to save all the plots in a pdf file, you’d do something like that: pdf(&quot;Plots/plots_fits.pdf&quot;,height=6, width=8) for(f in frubis){ p &lt;- ggplot(data=subset(spec, name==gsub(&quot;.txt&quot;,&quot;&quot;,f)),aes(x=w)) + geom_point(aes(w,Int))+ labs(x=&quot;Raman Shift [1/cm]&quot;, y=&quot;Intensity [arb. units]&quot;)+ ggtitle(gsub(&quot;.txt&quot;,&quot;&quot;,f))+ geom_line(aes(w,ytot),color=&quot;red&quot;)+ geom_area(aes(w,y1),fill=&quot;orange&quot;, alpha=0.1)+ geom_area(aes(w,y2),fill=&quot;royalblue&quot;, alpha=0.1)+ theme_bw() print(p) } dev.off() where the line print(p) is necessary, since ggplot does not output plots when embedded in a for loop. Now we can also plot the evolution of the fit parameters. Let’s only look at the position of the peaks: p &lt;- ggplot(data=fitpar, aes(x=name, y=fit)) + geom_point(data=subset(fitpar, param==&quot;x01&quot;), size=2)+ geom_point(data=subset(fitpar, param==&quot;x02&quot;), color=&quot;red&quot;, size=2)+ theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust=1)) ggplotly(p) And voilà! in a few lines of code, you have treated a number of spectra in the same manner, plotted the fits, obtained the fitting parameters and deducted the corresponding pressure. You are now ready to get to work! "],
["writing-documents-with-rmarkdown.html", "11 Writing documents with Rmarkdown 11.1 What is markdown? 11.2 … and Rmarkdown? 11.3 Further readings 11.4 Example 11.5 Compilation 11.6 Exercise", " 11 Writing documents with Rmarkdown 11.1 What is markdown? Markdown is a simplified language that can be used to produce a variety of rich documents: a single .md file can be compiled and outputted to .docx, .odt, .html, .rtf, .pdf or .tex. This output format as well as various options (font size, template, table of contents, numbered sections…) are specified in a YAML header, i.e. text between two lines like that --- (we’ll see an example later). In markdown can be embedded \\(\\LaTeX\\) code for displaying math expressions, html tags for more complicated html stuff, and the rest of the formatting is given by a few easy commands: # Title ## sub-title ### sub-sub-title ... ###### sub_6-title **bold** *italic* [link](http://google.com/) ![image caption](image.png) Table: | | | |---|---| | | | Unordered list: - bla - bla bla Ordered list: 1. bla 1. bla bla You can also add in-line code by writing text between back-ticks: Text with `in-line code` will render as: Text with in-line code For more commands, you can for example get a digested cheat-sheet here and a tutorial here. 11.2 … and Rmarkdown? Rmarkdown is basically the same thing as markdown (extension: .Rmd instead of .md), with the difference that code chunks in which you specify the language between accolades will be computed and the result will be displayed. ```r # Not computed 1+1 ``` ```{r} # Computed 1+1 ``` ## [1] 2 And in-line code can be computed and rendered: In-line code 3 will render as: In-line code 3. This very webpage is fully written in Rmarkdown (you can download the Rmd file if you click the link in the top banner). Rmarkdown supports a number of languages: names(knitr::knit_engines$get()) ## [1] &quot;awk&quot; &quot;bash&quot; &quot;coffee&quot; &quot;gawk&quot; &quot;groovy&quot; ## [6] &quot;haskell&quot; &quot;lein&quot; &quot;mysql&quot; &quot;node&quot; &quot;octave&quot; ## [11] &quot;perl&quot; &quot;psql&quot; &quot;Rscript&quot; &quot;ruby&quot; &quot;sas&quot; ## [16] &quot;scala&quot; &quot;sed&quot; &quot;sh&quot; &quot;stata&quot; &quot;zsh&quot; ## [21] &quot;highlight&quot; &quot;Rcpp&quot; &quot;tikz&quot; &quot;dot&quot; &quot;c&quot; ## [26] &quot;fortran&quot; &quot;fortran95&quot; &quot;asy&quot; &quot;cat&quot; &quot;asis&quot; ## [31] &quot;stan&quot; &quot;block&quot; &quot;block2&quot; &quot;js&quot; &quot;css&quot; ## [36] &quot;sql&quot; &quot;go&quot; &quot;python&quot; &quot;julia&quot; &quot;sass&quot; ## [41] &quot;scss&quot; &quot;theorem&quot; &quot;lemma&quot; &quot;corollary&quot; &quot;proposition&quot; ## [46] &quot;conjecture&quot; &quot;definition&quot; &quot;example&quot; &quot;exercise&quot; &quot;proof&quot; ## [51] &quot;remark&quot; &quot;solution&quot; And python and R code chunks can communicate thanks to the reticulate package. So… are you starting to see the power of this tool…? Basically, you can use the best language for each task and combine it in a single Rmd file that will display text and images that are computed at each compilation of the Rmd file: you can fully automatize your data treatment and reporting. Example: chunk 1: bash, call a program that creates some files chunk 2: python, call a program that do some big computation on these files chunk 3: r, plot the data 11.3 Further readings To see all about Rmarkdown and combining languages in a single document: code chunks languages Rmarkdown cheatsheet Rmarkdown cookbook 11.4 Example Create an example.Rmd file with the following YAML header (the indentation is important): --- title : Your Title author : John Doe date : 03/07/2019 output : word_document: reference_docx: path/to/word-template.docx pandoc_args: [&quot;--filter&quot;, &quot;pandoc-fignos&quot;] pdf_document: latex: xelatex fig_caption: true keep_tex: true pandoc_args: [&quot;--filter&quot;, &quot;pandoc-fignos&quot;] beamer_presentation: keep_tex: true html_document: toc: yes highlight: tango number_sections: false pandoc_args: [&quot;--filter&quot;, &quot;pandoc-fignos&quot;] html_notebook: toc: yes highlight: tango number_sections: false pandoc_args: [&quot;--filter&quot;, &quot;pandoc-fignos&quot;] bibliography: &quot;path/to/biblio.bib&quot; csl: &quot;path/to/nature.csl&quot; --- How to understand this header: ---: surrounds the YAML header. The body comes after that. title, author and date: easy. The date can automatically be set to the current one by setting it to r format(Sys.time(), '%d/%m/%Y'). output: this tells pandoc the output format you want. When compiling, the compiler will only look to the first entry – in this case, word_document. So you don’t need to put all these entries if you want a clean(er) code, but I like to have all these output possibilities written there, then I just have to switch the first entry to the one I want when I want to change the output format. The difference between html_document and html_notebook is that in notebooks you can fold/unfold the code chunks. reference_docx: tells pandoc the reference style (template) to use. Just write a dummy .docx file in which you edit the style, save it as word-template.docx, and you’re good to go. latex: the \\(\\LaTeX\\) engine. You can also use pdflatex, for example. keep_tex: when pandoc compiles your markdown file to a PDF, it goes through the intermediate step of creating a .tex file. You can decide to keep it for tweaking the style of the PDF output, like you would normally do with a .tex file. fig_caption: allows for figure caption. toc: creates a table of contents. number_sections: allows for section numbering. highlight: syntax highlighting theme for the code chunks. pandoc_args: add pandoc-eqnos or pandoc-tablenos if you want to number equations or tables. bibliography: path to your .bib file. To create a bibliography, add a # References header at the end of your document. csl: path to the bibliography style for the output – in this example, nature.csl. Find your style or edit your own. There are many other options, but with this you’ll fulfill most of your needs. Now you can start adding some content, like: --- title: &quot;The title&quot; output: html_document --- # First section ## First subsection I am writing _italic_ and __bold__ stuff. - This is an item - This is another item with a citation [@Bibkey] # Second section ## First subsection This is a text with a footnote[^1]. This is an image with a caption: ![Image with a caption](https://cdn.foliovision.com/images/2017/03/i-love-markdown.png) While this image has no caption ![Image with no caption because I didn&#39;t skip a line](http://markdown-here.com/img/icon256.png) Here&#39;s a code chunk in R: ```{r} x &lt;- seq(0,10,.1) plot(x, sin(x)) ``` And one in python: ```{python} x = 1+1 ``` # References [^1]: This is a footnote. Note that when you choose to output to an html format, you can’t use PDF images: use .svg (pdf2svg) or other non vectorial images. What’s nice with html output, it’s that you can include interactive figures with plotly like we saw in the previous sections. Of course, this won’t work with static documents like PDF or Word… For cross referencing to figures and tables, use output: bookdown::html_document2 instead of output: html_document (requires the package bookdown), and see here for details. 11.5 Compilation To knit your Rmd file to the desired output, in Rstudio, click the little triangle next to the “Knit” button, like this: The corresponding output file will be created in the same folder. 11.6 Exercise Exercise 1 Create a new Rmd document in Rstudio, fill it with what you want, and output it in different formats. Exercise 2 Create an html experimental logbook doing all the data treatment in the example in the previous section. "],
["graphical-interfaces-with-shiny.html", "12 Graphical interfaces with Shiny", " 12 Graphical interfaces with Shiny "]
]
